\section{Conclusion}
\label{sec:conclusion}
This paper measured conversational persistence on Moltbook during its first week
of public operation using a two-part definition: direct-reply incidence and
conditional reply speed. In this snapshot, the core pattern is
low-incidence/very-fast-conditional response: horizon-standardized incidence is
\(p_{5\mathrm{m}}=9.42\%\) and \(p_{1\mathrm{h}}=9.82\%\), while conditional
reply times are concentrated in seconds (\(t_{50}=4.55\) seconds,
\(t_{90}=50.05\) seconds, \(t_{95}=132.23\) seconds). The in-window ever-reply
share (9.60\%) is a secondary descriptive metric. Most comments receive no
direct reply, reciprocal interaction is uncommon, and thread geometry is
shallow and root-heavy.

Model-to-observable validation shows tight calibration for reply incidence
overall and across key strata, while the same model overpredicts non-root
branching and deep-tail depth probabilities. A one-parent-per-thread robustness
check lowers pooled incidence but leaves conditional median speed nearly
unchanged, indicating that the central limitation is whether replies occur, not
how fast they arrive once they do. The kernel half-life diagnostic is
informative as a secondary exponential-equivalent timescale readout but is not
the primary persistence metric.

For context, a contemporaneous Reddit corpus analyzed with the same estimators
shows substantially deeper threads, higher direct-reply incidence, and
hour-scale persistence diagnostics; this baseline contrast remains observational
and non-causal.
The main next step is longitudinal measurement with richer exposure controls
(visibility, ranking, notifications) and richer agent-level models, enabling
sharper tests of lever-based intervention hypotheses such as memory aids,
thread summarization, and explicit re-entry prompts, including trade-offs across
incidence, conditional speed, and thread depth. In this first-week snapshot,
the evidence is consistent with the hypothesis that early agent social
platforms are more effective at initiating interactions than sustaining
multi-turn conversations without additional coordination scaffolds. These
design implications should be interpreted as model-consistent decision-support
hypotheses, not as experimentally validated causal intervention effects.
