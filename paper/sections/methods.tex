\section{Methods}
\label{sec:methods}

We describe our empirical methodology for (1) characterizing conversation geometry,
(2) estimating interaction half-life, (3) detecting periodic signatures, and
(4) executing a coarse matched cross-platform comparison.

\subsection{Conversation Geometry}
\label{sec:methods:geometry}

We compute structural properties of comment trees that characterize ``conversation shape'' independently of temporal dynamics.

\subsubsection{Depth Distribution}

For each thread $j$, we compute the depth $d_{jn}$ of every comment using \cref{eq:depth} and record the maximum depth $D_j$. We report:
\begin{itemize}
    \item The empirical distribution of $D_j$ across threads,
    \item Mean and median depth,
    \item The proportion of threads reaching depth $k$ for $k = 1, 2, \ldots, 10$.
\end{itemize}

Under our model (\cref{prop:depth-bound}), $\Prob(D_j \geq k) \leq \mu^k$. We estimate
the effective branching ratio $\hat{\mu}$ by fitting this exponential bound to the
empirical tail distribution via zero-intercept least squares on log-probabilities,
using $k = 1, 2, \ldots, \max(D_j)$.  Because the depth distribution is computed
conditional on threads with at least one comment ($N = 34{,}730$),
$\Prob(D_j \geq 1) = 1$ by construction; the $k = 1$ point anchors the regression
at zero and the fit is driven by $k \geq 2$.  The resulting $\hat{\mu}$ should be
interpreted as an \emph{effective non-root reproduction parameter}
(\cref{rem:two-type}), not a literal unconditional offspring mean for the root post.

\subsubsection{Branching Factor}

The \emph{branching factor} of a node is its number of direct children. We compute:
\begin{itemize}
    \item Mean branching factor by depth level, $\bar{c}_k := \E[\text{children of nodes at depth } k]$,
    \item Root branching factor (direct replies to the post),
    \item Distribution of branching factors across all nodes.
\end{itemize}

Star-shaped trees (many direct replies, few deep chains) exhibit high root branching factor and rapidly declining $\bar{c}_k$.

\subsubsection{Reciprocity and Back-and-Forth}

We measure conversational reciprocity---the extent to which agents respond to each other---via:
\begin{itemize}
    \item \textbf{Dyadic reciprocity}: For each ordered pair of agents $(i, j)$ appearing in the same thread, count replies from $i$ to $j$ and from $j$ to $i$. Reciprocity is the fraction of dyads with bidirectional replies.
    \item \textbf{Chain length}: A \emph{reciprocal chain} is a maximal sequence of consecutive replies alternating between two agents. We report the distribution of chain lengths.
\end{itemize}

Low reciprocity and short chains indicate ``broadcast'' rather than ``conversational'' dynamics.

\subsubsection{Re-Entry Rate}

We compute the re-entry rate $\text{RE}_j$ (\cref{eq:reentry-rate}) for each thread: the fraction of comments from agents who have previously commented in the same thread. We report:
\begin{itemize}
    \item Distribution of $\text{RE}_j$ across threads,
    \item Relationship between $\text{RE}_j$ and thread size (larger threads may mechanically have higher re-entry),
    \item Agent-level re-entry frequency (how often each agent returns to threads they've commented on).
\end{itemize}

\subsection{Interaction Half-Life Estimation}
\label{sec:methods:halflife}

Our primary goal is estimating the decay rate $\beta$ (equivalently, half-life $h = \ln 2 / \beta$) governing how quickly conversational engagement fades.

\subsubsection{Survival Analysis Framework}

We frame half-life estimation as a survival analysis problem. For each comment $m$ in thread $j$, define the \emph{survival time} $S_{jm}$ as the time until the \emph{next} direct reply to $m$:
\begin{equation}
\label{eq:survival-time}
S_{jm} := \min\{t_{jn} - t_{jm} : p_{jn} = m, n > m\}.
\end{equation}
If $m$ receives no replies, $S_{jm}$ is right-censored at the thread's observation window.

Under the model (\cref{eq:reply-intensity}), conditional on the availability function $b(t)$, $S_{jm}$ follows an inhomogeneous exponential distribution with hazard
\begin{equation}
\label{eq:hazard}
\lambda(s \mid t_{jm}) = b(t_{jm} + s) \, \alpha_{a_{jm}} \, e^{-\beta_{a_{jm}} s}.
\end{equation}

\begin{remark}[Estimand interpretation]
\label{rem:estimand}
The \emph{reply-kernel half-life} $\hat{h} = \ln 2 / \hat{\beta}$ is a
\textbf{kernel decay timescale}: it characterizes how quickly the instantaneous
hazard of receiving a direct reply falls as a parent comment ages. It is
\emph{not} the median thread lifetime or the time at which 50\% of all
comments have arrived. Because most parent comments receive no direct reply
in-window (high censoring fraction), the estimated half-life reflects the
concentration of observed replies in the first seconds to minutes after a
parent is posted. A short half-life combined with heavy censoring describes a
\emph{bursty} reply process: if a direct reply occurs at all, it occurs
quickly; otherwise the parent comment typically receives no direct reply.
\end{remark}

\subsubsection{Parametric Estimation}

We estimate $\beta$ via maximum likelihood under exponential and Weibull survival models:

\paragraph{Exponential model.} Assume constant $b(t) = 1$ and homogeneous $\alpha, \beta$. The log-likelihood for observed survival times $\{s_m\}$ with censoring indicators $\{\delta_m\}$ is:
\begin{equation}
\label{eq:exponential-ll}
\ell(\alpha, \beta) = \sum_m \left[ \delta_m \left( \log \alpha - \beta s_m \right) - \frac{\alpha}{\beta} \left(1 - e^{-\beta s_m}\right) \right].
\end{equation}
We maximize numerically to obtain $(\hat{\alpha}, \hat{\beta})$ and report $\hat{h} = \ln 2 / \hat{\beta}$.

\paragraph{Weibull model.} To allow for non-exponential decay, we fit a Weibull survival model with shape parameter $\gamma$:
\begin{equation}
\label{eq:weibull-survival}
S(s) = \exp\!\left(-\left(\frac{s}{\lambda}\right)^\gamma\right).
\end{equation}
The case $\gamma = 1$ recovers the exponential; $\gamma < 1$ indicates decreasing hazard (early replies more likely), while $\gamma > 1$ indicates increasing hazard.

\subsubsection{Reply Probability vs.\ Reply Timing}

Given heavy censoring, we report a two-part decomposition in addition to $\hat{\beta}$:
\begin{itemize}
    \item \textbf{Observed in-window reply probability}
    \(p_{\mathrm{obs}}=\Pr(\text{parent receives} \ge 1 \text{ direct reply in window})\),
    estimated as event fraction in the primary survival sample.
    \item \textbf{Conditional timing summary}: median time-to-first-direct-reply among
    observed events.
    \item \textbf{Implied eventual reply probability under fitted exponential model (diagnostic only)}:
    \(p_{\infty}=1-\exp(-\hat{\alpha}/\hat{\beta})\), where
    \(\hat{\alpha}/\hat{\beta}\) is integrated reply mass under the fitted hazard.
\end{itemize}
This separates \emph{whether} replies occur from \emph{how quickly} they occur when they do.

\paragraph{Agent heterogeneity (implemented summary).} In this analysis pass, we report
stratified pooled estimates rather than a full mixed-effects survival model: half-life
and reply-probability summaries by submolt category and by agent-level proxies
(\texttt{is\_claimed} status and follower-count bins \(\{0,1\text{--}9,10+\}\)).

\subsubsection{Stratified Estimates}

We compute half-life estimates stratified by:
\begin{itemize}
    \item \textbf{Submolt category}: Builder/Technical, Philosophy/Meta, Social/Casual, etc.,
    \item \textbf{Agent groups}: claimed vs.\ unclaimed accounts and follower-count bins
    (\(0,1\text{--}9,10+\)).
\end{itemize}

\subsubsection{Confidence Intervals and Uncertainty}

We report 95\% confidence intervals using cluster bootstrap resampling at the thread level.

\subsection{Periodicity Detection}
\label{sec:methods:periodicity}

Our model predicts periodic structure in comment arrivals at the heartbeat frequency ($\sim$4 hours). We test this via spectral analysis.

\subsubsection{Aggregate Activity Time Series}

We construct a time series of comment counts binned at 15-minute intervals for the primary
specification. Because the canonical comment timeline contains a long coverage gap, we first
segment the event stream at gaps $>6$ hours and analyze the longest contiguous segment. Let
$C_t$ denote the count in bin $t$ for that segment. We apply standard preprocessing:
\begin{itemize}
    \item Log-transform: $Y_t = \log(C_t + 1)$ to stabilize variance,
    \item Detrending: subtract a 24-hour moving average to remove diurnal drift,
    \item Windowing: apply a Hanning window before spectral estimation.
\end{itemize}

\subsubsection{Spectral Analysis}

We estimate the power spectral density (PSD) via Welch's method with overlapping segments.
We test for peaks at the expected heartbeat frequency
$f_\tau = 1/\tau \approx 1/(4\text{ hours}) = 0.25\text{ hr}^{-1}$ by:
\begin{itemize}
    \item Comparing observed power at $f_\tau$ to a red-noise null from an AR(1) process
    fit to the detrended series,
    \item Estimating Monte Carlo $p$-values using 2,000 AR(1) simulations for both
    Fisher's $g$ and the target-frequency power.
\end{itemize}
As a robustness check, we repeat the target-frequency and dominant-frequency analysis with
5-minute and 30-minute bins on the same contiguous segment.

\subsubsection{Agent-Level Autocorrelation}

For agents with $\geq 10$ comments in the contiguous periodicity segment, we compute lagged
autocorrelation on each agent's 15-minute binned activity process. We report:
\begin{itemize}
    \item Mean autocorrelation at lag 4 hours,
    \item Bootstrap confidence intervals over agents.
\end{itemize}

\subsection{Cross-Platform Comparison}
\label{sec:methods:comparison}

To assess whether Moltbook dynamics differ from human-driven platforms, we compare against matched Reddit threads.
In this revision, we execute a coarse matched observational comparison using
\texttt{analysis/08\_cross\_platform\_matched\_analysis.py} (run ID
\texttt{run\_20260206-182842Z}).

\subsubsection{Matching}

Naive cross-platform comparisons confound platform differences with selection effects (e.g., threads that attract early engagement differ systematically from those that do not). We employ coarsened exact matching \citep{iacus2012causal} to align Moltbook and Reddit threads on:
\begin{itemize}
    \item \textbf{Early engagement}: thread comment count in the first 30 minutes, computed from
    \texttt{thread\_events} and coarsened into bins \(\{0,\;1\text{--}2,\;3\text{--}5,\;6\text{--}10,\;11+\}\),
    \item \textbf{Topic category}: deterministic coarse mapping. Moltbook
    \((\texttt{Builder/Technical}\rightarrow\texttt{tech},
    \texttt{Philosophy/Meta}\rightarrow\texttt{meta},
    \texttt{Social/Casual}\rightarrow\texttt{general},
    \texttt{Creative}\rightarrow\texttt{general},
    \texttt{Other}\rightarrow\texttt{general},
    \texttt{Spam/Low-Signal}\rightarrow\texttt{spam})\);
    Reddit
    \((\texttt{MachineLearning}, \texttt{Python}, \texttt{datascience},
    \texttt{learnprogramming}, \texttt{programming}\rightarrow\texttt{tech},
    \texttt{artificial}\rightarrow\texttt{meta})\),
    \item \textbf{Time of posting}: exact UTC hour bin (\(0,\ldots,23\)).
\end{itemize}

Threads are assigned to exact strata defined by
\((\texttt{topic\_coarse},\texttt{post\_hour\_bin},\texttt{early\_engagement\_bin})\).
Within each stratum, we sort Moltbook and Reddit threads by
\((\texttt{early\_comments\_30m}, \texttt{created\_at\_utc}, \texttt{thread\_id})\) and
take one-to-one matches up to \(\min(n_M, n_R)\). This yields deterministic 1:1 pairing
without random tie-breaking.

\subsubsection{Outcome Metrics}

For each matched pair, we compute:
\begin{itemize}
    \item \textbf{Total comments} \(N\),
    \item \textbf{Maximum depth} \(D\),
    \item \textbf{Unique participants},
    \item \textbf{Thread duration} (hours),
    \item \textbf{Re-entry rate} \(\mathrm{RE}\).
\end{itemize}
Interaction half-life is additionally estimated on the matched-thread subsets for each
platform (not pairwise at thread level) using the same reply-kernel survival construction as
platform-side analyses.

\subsubsection{Statistical Testing}

We test for platform differences using:
\begin{itemize}
    \item \textbf{Paired tests}: two-sided Wilcoxon signed-rank tests on matched-pair differences,
    \item \textbf{Effect sizes}: paired Cohen's \(d\),
    \item \textbf{Uncertainty}: bootstrap 95\% confidence intervals for mean paired differences
    (1,000 resamples over matched pairs),
    \item \textbf{Balance diagnostics}: standardized mean differences (SMD) before/after matching;
    for categorical controls we report level-wise SMD and total variation distance.
\end{itemize}

\subsubsection{Sensitivity Analyses}

The present cross-platform pass is intentionally coarse. We treat caliper variants,
alternative topic maps, and richer causal estimators as planned follow-up analyses rather than
reporting them post hoc.

\subsection{Implementation}
\label{sec:methods:implementation}

All analyses are implemented in Python. The Reddit full-scale run reported here uses
\texttt{analysis/07\_reddit\_only\_analysis.py} with run ID
\texttt{attempt\_scaled\_20260206-142651Z} (seed 20260206; censor boundary 4 hours; 400
bootstrap replications; 2,000 AR(1) simulations), after run-scoped validation by
\texttt{analysis/05\_reddit\_validate.py}. Cross-platform matched analysis uses
\texttt{analysis/08\_cross\_platform\_matched\_analysis.py} with run ID
\texttt{run\_20260206-182842Z} (seed 20260206; 1,000 paired bootstrap replications; 400
thread-cluster bootstrap replications for matched-subset half-life). Software dependencies,
versions, and end-to-end reproduction instructions are documented in
\Cref{sec:reproducibility}.
