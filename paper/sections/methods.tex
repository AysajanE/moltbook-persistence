\section{Estimation and Empirical Procedures}
\label{sec:methods}

Estimands are defined in \Cref{sec:model:estimands}. This section focuses on
estimation algorithms and empirical procedures. Low-level operational settings
(binning, detrending, bootstrap mechanics, and matching construction) are
reported in \Cref{sec:appendix:operational-details}.

\subsection{Conversation Geometry}
\label{sec:methods:geometry}

For each thread \(j\), we compute node depths from \cref{eq:depth}, record the
maximum depth \(D_j\), and summarize the empirical depth distribution with mean
maximum depth, median maximum depth, and tail probabilities
\(\Prob(D_j \ge k)\) for \(k=1,\ldots,10\). Using the model implication in
\cref{prop:depth-bound}, we estimate an effective depth-tail slope
\(\hat{s}_{\mathrm{depth}}\) by zero-intercept least squares on
\(\log \Prob(D_j \ge k)\). Because the analysis conditions on threads with at
least one comment, \(\Prob(D_j \ge 1)=1\) by construction; the fit is therefore
identified by \(k\ge2\). Since \cref{prop:depth-bound} is an inequality,
\(\hat{s}_{\mathrm{depth}}\) is reported as a descriptive depth-tail decay
summary rather than as an exact reproduction-mean estimator; branching
interpretations are heuristic (\cref{rem:two-type}).

We additionally compute branching-factor profiles by depth,
\(\bar c_k = \E[\text{children at depth }k]\), including the root branching
factor, to distinguish root-heavy star patterns from deeper cascades.

Reciprocity is measured from directed dyads within threads as the fraction of
dyads with bidirectional replies, and reciprocal-chain length is defined as the
maximal alternating exchange between two agents. Re-entry is measured by
\(\mathrm{RE}_j\) in \cref{eq:reentry-rate}. Missing-author-identifier handling rules
are deterministic and documented in \Cref{sec:appendix:operational-details}.

\subsection{Two-Part Reply Dynamics Estimation}
\label{sec:methods:two-part}

For each at-risk comment (candidate parent)
\(m\) in thread \(j\), we define first-direct-reply survival time
\begin{equation}
\label{eq:survival-time}
S_{jm} := \min\{t_{jn} - t_{jm} : p_{jn}=m,\; n>m\}.
\end{equation}
If no direct reply is observed, the unit is right-censored at the observation
boundary. Because the canonical timeline contains a 41.7-hour coverage gap,
we do not impute unobserved replies across that interval.

\paragraph{Part 1: incidence model.}
For each parent unit, event indicator \(\delta_m\) is modeled with a
complementary log-log (cloglog) generalized linear model:
\begin{equation}
\label{eq:methods-incidence-cloglog}
\log\!\left[-\log(1-\Prob(\delta_m=1\mid x_m))\right]=x_m^\top\eta,
\end{equation}
with \(x_m\) including categorical indicators for submolt category and
claimed-status group. Inference uses two-way clustered covariance by thread and
author to address within-thread dependence and repeated-author dependence.

\paragraph{Part 2: conditional timing model.}
Among replied parents \((\delta_m=1)\), we report empirical conditional-time
estimands directly:
\(\tilde s_{0.5}\), \(\tilde s_{0.9}\), \(\tilde s_{0.95}\),
\(\Prob(T_m\le 30\mathrm{s}\mid \delta_m=1)\), and
\(\Prob(T_m\le 5\mathrm{min}\mid \delta_m=1)\). We also report their
unconditional counterparts \(\Prob(\delta_m=1,T_m\le t)\) for
\(t\in\{30\mathrm{s},5\mathrm{min}\}\). For parametric shape diagnostics, we
fit Weibull and lognormal-style alternatives to \(T_m\mid \delta_m=1\).

Under \cref{eq:reply-intensity}, the parent-age hazard is
\begin{equation}
\label{eq:hazard}
\lambda(s \mid t_{jm}) = b(t_{jm}+s)\,\alpha_{a_{jm}}\,e^{-\beta_{a_{jm}}s}.
\end{equation}
The estimation model uses \(b(t)=1\) as a timescale-separation approximation for
identifying \(\beta\), while periodic modulation is tested separately at the
aggregate level (\Cref{sec:methods:periodicity}).

\begin{remark}[Estimand interpretation]
\label{rem:estimand}
The \emph{reply-kernel half-life} \(\hat h = \ln 2/\hat\beta\) is a kernel-decay
timescale for direct-reply hazard. It is not a median thread lifetime.
With heavy censoring, short \(\hat h\) indicates that replies, when they occur,
arrive quickly relative to parent age.
\end{remark}

We estimate \((\alpha,\beta)\) by maximum likelihood under an exponential-kernel
hazard model with constant \(b(t)=1\):
\begin{equation}
\label{eq:exponential-ll}
\ell(\alpha,\beta)=\sum_m\left[\delta_m(\log\alpha-\beta s_m)-\frac{\alpha}{\beta}\left(1-e^{-\beta s_m}\right)\right].
\end{equation}
We also fit a Weibull alternative,
\begin{equation}
\label{eq:weibull-survival}
S(s)=\exp\!\left(-\left(\frac{s}{\lambda}\right)^\gamma\right),
\end{equation}
to assess departures from exponential decay.

Given high censoring, we report incidence and conditional-speed estimands as
primary readouts; \(p_\infty=1-\exp(-\hat\alpha/\hat\beta)\) and half-life are
kept as secondary diagnostics. We report stratified pooled estimates by submolt
category and claim status, plus one-parent-per-thread sensitivity readouts to
bound within-thread clustering effects.

Uncertainty is quantified with thread-cluster bootstrap confidence intervals
using fixed deterministic resampling settings (\Cref{sec:appendix:operational-details}).

\subsection{Periodicity Detection}
\label{sec:methods:periodicity}

To test for heartbeat-scale periodicity, we analyze the longest contiguous
coverage segment and transform binned counts to a detrended series \(Y_t\) using
log-count stabilization and moving-average detrending.

We estimate PSD with Welch's method on \(Y_t\). We test the target frequency
\(f_\tau = 1/\tau \approx 0.25\,\mathrm{hr}^{-1}\) using two statistics:
Fisher's \(g=\max_f I(f)/\sum_f I(f)\), and target-frequency power
\(T_\tau=I(f_\tau^\star)\), where \(I(f)\) is the positive-frequency periodogram
of \(Y_t\) and \(f_\tau^\star\) is the nearest Fourier frequency to 0.25
hr\(^{-1}\).

Null calibration uses a first-order autoregressive (AR(1)) process fit directly to \(Y_t\):
\(Y_t=\phi Y_{t-1}+\varepsilon_t\), with \(\phi\) estimated by least squares and
innovation scale from residual standard deviation. Monte Carlo exceedance
\(p\)-values are computed for both statistics, and bin-width robustness checks
are run on the same contiguous segment. Exact binning and simulation settings
are reported in \Cref{sec:appendix:operational-details}.

To complement PSD-based tests, we run an event-time modulo-\(\tau\) circular
uniformity test on raw event timestamps. With
\(\theta_n := 2\pi\big((t_n \bmod \tau)/\tau\big)\), the Rayleigh resultant
length is \(R=\left|\frac{1}{N}\sum_{n=1}^N e^{i\theta_n}\right|\) and test
statistic is \(Z=NR^2\). We calibrate the \(p\)-value by Monte Carlo and report
the mean phase. Detectability is summarized with a power curve over circular
concentration amplitudes \(\kappa\), using the observed \(N\), \(\alpha\), and
critical \(Z\).

At agent level, we compute lagged autocorrelation on 15-minute activity series
for agents with at least 10 comments in the contiguous segment and report the
mean lag-4-hour autocorrelation with bootstrap confidence intervals (operational
settings in \Cref{sec:appendix:operational-details}).

\subsection{Cross-Platform Comparison}
\label{sec:methods:comparison}

To contextualize Moltbook against a human-platform baseline, we run a coarse
matched observational comparison with Reddit threads.

Matching uses coarsened exact strata on early engagement, coarse topic, and UTC
posting hour, then deterministic one-to-one pairing within shared strata.
Exact strata definitions and pairing rules are documented in
\Cref{sec:appendix:operational-details}.

For each matched pair, we compute total comments, maximum depth, unique
participants, thread duration, and re-entry rate. Reply-kernel half-life is
also estimated on matched-thread subsets for each platform (platform-level
estimation, not thread-level paired survival effects).

Inference uses two-sided Wilcoxon signed-rank tests on paired differences,
paired Cohen's \(d\), and bootstrap 95\% confidence intervals for mean paired
differences. Balance diagnostics include
standardized mean differences before and after matching, plus level-wise
categorical diagnostics and total variation distance. Resampling mechanics are
reported in \Cref{sec:appendix:operational-details}.

All analyses are run in Python with fixed seeds and deterministic preprocessing;
manuscript-level reproducibility metadata are provided in
\Cref{sec:reproducibility}.
