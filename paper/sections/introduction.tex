\section{Introduction}
\label{sec:introduction}

Recent advances in large language models (LLMs) have enabled a new class of autonomous artificial intelligence (AI) agents capable of sustained interaction with digital environments. One manifestation of this capability is \emph{Moltbook}, a social network launched in January 2026 that restricts posting privileges to AI agents while permitting human observation \citep{willison2026moltbook}. In this paper, an \emph{AI agent account} denotes an account whose posting and commenting actions are generated by an LLM-driven agent process rather than direct human operation. In the first archived week, the platform accumulated over 25{,}000 such agent accounts and 119{,}677 posts \citep{simulamet2026observatoryarchive}, creating a large, accessible dataset of agent-to-agent interaction.

This emergence of agent-populated social platforms raises fundamental questions about collective AI behavior. Can autonomous agents sustain the extended, multi-turn dialogues necessary for meaningful collaboration? How might architectural constraints---particularly context-window limitations and periodic activation schedules---shape the temporal dynamics of agent discourse? And what distinguishes agent-driven conversations from human-driven ones in structural and temporal terms?

\subsection{Motivation and Research Questions}

Early public commentary proposed that Moltbook agents may be better at
\emph{initiating} projects than \emph{sustaining} them and may follow roughly
4-hour check-in routines \citep{alexander2026afterweekend,willison2026moltbook}.
We use these statements as qualitative hypothesis motivation only, not as
factual evidence; empirical claims in this paper are derived from the archived
Observatory data. Because per-account heartbeat events are unobserved, we test
only aggregate periodic signatures, allowing for weak detectability under
dephasing/jitter. This framing is paired with finite context windows, which
motivate tests of rapid within-thread staleness.

Conversation persistence can be interpreted through canonical constructs in
service systems and stochastic-process modeling. Aggregate availability and
heartbeat schedules correspond to time-varying service capacity and cyclic
service regimes \citep{whitt2004efficiency,jouini2010online}. Staleness decay
corresponds to abandonment and impatience mechanisms in waiting systems
\citep{whitt2004efficiency,reed2012hazard,jouini2010online}. Reply incidence
corresponds to completion/throughput outcomes under constrained capacity, and
thread depth corresponds to branching stability versus subcriticality
\citep{harris1963theory}. This mapping motivates the measurement-target design
used in this study.

From an operations research and management science (OR/MS) decision-support perspective, the platform is a distributed
service system in which pending parent comments are competing jobs for limited
agent attention. The operational design problem is to allocate limited
intervention budget across incidence-lift levers (for example resurfacing or
visibility reminders) versus timing-lift levers (for example memory/context
support) to maximize downstream coordination throughput, such as
\(\Prob(D_j\ge K)\) and re-entry incidence.
In this framing, our contribution is not only descriptive: the incidence margin
diagnoses participation bottlenecks, while the conditional timing margin
diagnoses latency bottlenecks, and the two margins define a policy-priority
control panel.

Our objective is to formalize and empirically validate a two-part control panel
for conversational persistence in Moltbook's first week: (i) direct-reply
incidence and (ii) conditional reply latency, with explicit mapping to
depth-throughput outcomes. In scope are this decomposition, its structural
consequences for depth, branching, reciprocity, and re-entry, and heterogeneity
analyses only when they sharpen interpretation of which margin constrains
coordination. Out of scope are dedicated thread-duration inference,
cross-platform baseline-comparison mechanics, and detailed periodicity
machinery as primary claims; thread duration is reported only as an ancillary
descriptive/contextual metric, and Reddit baseline context/periodicity are
treated as secondary contextual or supplementary analyses.

\paragraph{Identification scope.}
This paper reports observational measurement targets from archived first-week
data and does not identify causal intervention effects. Periodicity and
cross-platform baseline comparisons are contextual checks rather than primary
identification strategies. For heartbeat periodicity, we distinguish
statistical rejection of exact uniformity from practical signal strength:
at large \(N\), Rayleigh tests can reject uniformity even when concentration
is too small to imply meaningful global synchronization.
Accordingly, patterns described as consistent with architectural constraints are
also compatible with alternative platform-side explanations such as
ranking/visibility effects, moderation throttling, or batched/scheduled agent
execution.

\subsection{Hypotheses}
\label{sec:introduction:hypotheses}

Guided by the horizon-limited cascade framework (\Cref{sec:model}) and prior
qualitative commentary used for hypothesis motivation
\citep{willison2026moltbook, alexander2026afterweekend},
we test four hypotheses. H1a posits short exponential-equivalent kernel half-life
(diagnostic) values consistent with architectural staleness constraints. H1b
posits that heartbeat scheduling can
generate aggregate periodic structure near the hypothesized cadence
($\tau \approx 4$ hours) when check-ins are sufficiently synchronized; under
dephasing or jitter, aggregate detectability may be weak in finite samples.
H2 posits shallower, more root-concentrated Moltbook trees than human-platform
baselines, with lower reciprocity and conditioning-sensitive re-entry profiles; the
re-entry contrast is treated as conditioning-sensitive and may change direction
across baseline conditioning sets.
H3 posits topic-level moderation of persistence, including systematic differences
in kernel half-life diagnostic values and depth across submolts. H4 posits that
agent-level claim-status covariates are associated with variation in reply
incidence and conversational persistence.

We operationalize these hypotheses via the measurement targets defined in \Cref{sec:model}
and the estimators in \Cref{sec:methods}, and evaluate them in \Cref{sec:results}.
To make this mapping explicit, \Cref{tab:intro-roadmap} provides a compact
hypothesis-to-measurement-target roadmap with the corresponding empirical
readout sections.

\begin{table}[t]
\centering
\caption{Hypothesis roadmap: measurement targets, empirical readout location, and headline finding.}
\label{tab:intro-roadmap}
\begingroup
\setlength{\tabcolsep}{3pt}
\scriptsize
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{0.09\linewidth}>{\raggedright\arraybackslash}p{0.33\linewidth}>{\raggedright\arraybackslash}p{0.22\linewidth}>{\raggedright\arraybackslash}p{0.30\linewidth}@{}}
\toprule
\textbf{Hyp.} & \textbf{Measurement target(s)} & \textbf{Section where tested} & \textbf{Key result} \\
\midrule
H1a & Horizon-standardized incidence \(p_{5\mathrm{m}},p_{1\mathrm{h}}\), secondary \(p_{\mathrm{obs}}\), and conditional timing \(F_{T\mid\delta=1}\) (for example \(t_{50}, t_{90}\)). & \Cref{sec:results:decomposition,sec:results:summary}. & Supported: low incidence at fixed horizons with very fast conditional timing (low-incidence/fast-conditional-response split). \\
H1b & Modulo-\(4\)-hour phase concentration (\(R\)), Rayleigh statistic (\(Z\)), and coarse-grid detectability reference (\(\kappa^\star\)). & \Cref{sec:results:periodicity}. & Exact uniformity is rejected at large \(N\), but a strong aggregate 4-hour coherence claim is not supported because concentration is very small and dephased. \\
H2 & Thread-geometry summaries (\(D_j,\hat{s}_{\mathrm{depth}},\bar c_k\)), reciprocity, re-entry \(\mathrm{RE}_j\), and Reddit baseline contrasts under the same estimators. & \Cref{sec:results:structure,sec:results:reddit-full-scale,sec:results:summary}. & Partially supported: Moltbook is shallow and root-concentrated; baseline context is deeper; reciprocity/re-entry contrast is conditioning-sensitive. \\
H3 & Submolt-stratified incidence/timing measurement targets, kernel half-life diagnostic differences, and topic-level depth-tail checks. & \Cref{sec:results:heterogeneity,sec:results:summary}. & Partially supported: topic moderation is clear for incidence/timing; depth moderation is present but deep-tail levels remain small. \\
H4 & Agent-covariate associations (claim status) in the two-part incidence/timing readout, with stratified diagnostics. & \Cref{sec:results:agent-covariates,sec:results:summary}. & Partially supported: claim-status associations are sizable descriptively, with dependence-limited model-based precision. \\
\bottomrule
\end{tabular}
\endgroup
\end{table}

\subsection{Preview of Findings}

In this first-week snapshot, Moltbook conversations are predominantly star-shaped,
with minute-scale kernel half-life diagnostic values, low direct-reply
incidence, and minimal
reciprocity. Periodicity effect size is weak (\(r=0.0308\)); Rayleigh testing
rejects exact uniformity at large \(N\), but spectral diagnostics do not show a
strong 4-hour line.
A run-scoped Reddit baseline shows materially longer
persistence and deeper threads. Taken together, these patterns are compatible
with a ``low-incidence/fast-conditional-response'' regime and indicate that
incidence, not conditional latency, is the dominant operational bottleneck at
minute-to-hour horizons in this snapshot.

\subsection{Approach and Contributions}

Aligned to this objective, the paper delivers three contributions. First, we
formalize an OR diagnostic for horizon throughput \(q_h\): a decomposition into
incidence and conditional timing on a common risk set, with a derived
cost-adjusted priority rule for deciding whether to invest in participation
uplift or latency reduction (\Cref{sec:model:or-diagnostic}). This turns a
standard survival decomposition into a decision-support control panel. Second,
using the Moltbook Observatory Archive
\citep{simulamet2026observatoryarchive}, we provide an analytic
decision-support evaluation of that control panel using observed margins: we
quantify how incidence versus conditional timing changes propagate to depth and
re-entry-relevant coordination pressure under budgeted interventions. Third, we
differentiate this contribution from conversation-cascade studies that
typically emphasize unconditional delay or geometry summaries
\citep{crane2008robust,rizoiu2017expecting,gomez2013structure,aragon2017thread,meital2024branch}:
by separating incidence from conditional speed under right-censoring and then
mapping both to OR targets, we identify which margin is operationally binding
rather than treating persistence as a single aggregate statistic.

\subsection{Paper Organization}

The remainder of this paper is organized as follows. \Cref{sec:background}
reviews stochastic-process foundations for interaction persistence, then network structure and agent-platform context.
\Cref{sec:model} presents the minimal model and primary measurement targets.
\Cref{sec:data} describes data construction and preprocessing.
\Cref{sec:methods} details estimation and empirical procedures.
\Cref{sec:results} reports empirical findings and model-consistency checks.
\Cref{sec:discussion} interprets implications, including short downstream design
considerations. \Cref{sec:limitations} addresses limitations and ethical
considerations. \Cref{sec:conclusion} concludes with key takeaways and future
work. Reproducibility and data-availability statements are provided in the
required manuscript statements, and supplementary material provides extended
derivations and diagnostics.
