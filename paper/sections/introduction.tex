\section{Introduction}
\label{sec:introduction}

Recent advances in large language models (LLMs) have enabled a new class of autonomous artificial intelligence (AI) agents capable of sustained interaction with digital environments. One manifestation of this capability is \emph{Moltbook}, a social network launched in January 2026 that restricts posting privileges to AI agents while permitting human observation \citep{willison2026moltbook}. In this paper, an \emph{AI agent account} denotes an account whose posting and commenting actions are generated by an LLM-driven agent process rather than direct human operation. In the first archived week, the platform accumulated over 25{,}000 such agent accounts and 119{,}677 posts \citep{simulamet2026observatoryarchive}, creating a large, accessible dataset of agent-to-agent interaction.

This emergence of agent-populated social platforms raises fundamental questions about collective AI behavior. Can autonomous agents sustain the extended, multi-turn dialogues necessary for meaningful collaboration? How might architectural constraints---particularly context-window limitations and periodic activation schedules---shape the temporal dynamics of agent discourse? And what distinguishes agent-driven conversations from human-driven ones in structural and temporal terms?

\subsection{Motivation and Research Questions}

Early public commentary proposed that Moltbook agents may be better at
\emph{initiating} projects than \emph{sustaining} them and may follow roughly
4-hour check-in routines \citep{alexander2026afterweekend,willison2026moltbook}.
We use these statements as qualitative hypothesis motivation only, not as
factual evidence; empirical claims in this paper are derived from the archived
Observatory data. Because per-account heartbeat events are unobserved, we test
only aggregate periodic signatures, allowing for weak detectability under
dephasing/jitter. This framing is paired with finite context windows, which
motivate tests of rapid within-thread staleness.

Conversation persistence can be interpreted through canonical constructs in
service systems and stochastic-process modeling. Aggregate availability and
heartbeat schedules correspond to time-varying service capacity and cyclic
service regimes \citep{whitt2004efficiency,jouini2010online}. Staleness decay
corresponds to abandonment and impatience mechanisms in waiting systems
\citep{whitt2004efficiency,reed2012hazard,jouini2010online}. Reply incidence
corresponds to completion/throughput outcomes under constrained capacity, and
thread depth corresponds to branching stability versus subcriticality
\citep{harris1963theory}. This mapping motivates the measurement-target design
used in this study.

From an operations research and management science (OR/MS) decision-support perspective, the platform is a distributed
service system in which pending parent comments are competing jobs for limited
agent attention. The operational design problem is to allocate limited
intervention budget across incidence-lift levers (for example resurfacing or
visibility reminders) versus timing-lift levers (for example memory/context
support) to maximize downstream coordination throughput, such as
conversation depth and repeat participation (re-entry).
In this framing, our contribution is not only descriptive: the incidence margin
diagnoses participation bottlenecks, while the conditional timing margin
diagnoses latency bottlenecks, and the two margins define a policy-priority
control panel.

Our objective is to formalize and empirically validate a two-part control panel
for conversational persistence in Moltbook's first week: (i) direct-reply
incidence and (ii) conditional reply latency. We map these two margins to depth
and related thread-structure outcomes (branching, reciprocity, and re-entry).
We include heterogeneity analyses only when they clarify which margin constrains
coordination.

We do not attempt dedicated thread-duration inference, nor do we treat
cross-platform baseline comparison mechanics or detailed periodicity machinery
as primary claims. Thread duration is reported only as an ancillary descriptive
metric, and Reddit baseline context and periodicity are treated as secondary
contextual checks.

\paragraph{Identification scope}
This paper reports observational measurement targets from archived first-week
data and does not identify causal intervention effects. Periodicity and
cross-platform baseline comparisons are contextual checks rather than primary
identification strategies. For heartbeat periodicity, we distinguish
statistical rejection of exact uniformity from practical signal strength:
at large \(N\), Rayleigh tests can reject uniformity even when concentration
is too small to imply meaningful global synchronization.
Accordingly, patterns described as consistent with architectural constraints are
also compatible with alternative platform-side explanations such as
ranking/visibility effects, moderation throttling, or batched/scheduled agent
execution.

\subsection{Hypotheses}
\label{sec:introduction:hypotheses}

Guided by the horizon-limited cascade framework in \Cref{sec:model} and prior
qualitative commentary used for hypothesis motivation
\citep{willison2026moltbook, alexander2026afterweekend},
we test four hypotheses. H1a posits short exponential-equivalent kernel half-life
(diagnostic) values consistent with architectural staleness constraints. H1b
posits that heartbeat scheduling can
generate aggregate periodic structure near the hypothesized cadence
($\tau \approx 4$ hours) when check-ins are sufficiently synchronized; under
dephasing or jitter, aggregate detectability may be weak in finite samples.
H2 posits shallower, more root-concentrated Moltbook trees than human-platform
baselines, with lower reciprocity and conditioning-sensitive re-entry profiles; the
re-entry contrast is treated as conditioning-sensitive and may change direction
across baseline conditioning sets.
H3 posits topic-level moderation of persistence, including systematic differences
in kernel half-life diagnostic values and depth across submolts. H4 posits that
agent-level claim-status covariates are associated with variation in reply
incidence and conversational persistence.

We operationalize these hypotheses via the measurement targets defined in \Cref{sec:model}
and the estimators in \Cref{sec:methods}, and evaluate them in \Cref{sec:results}.
For compact orientation, H1a/H1b correspond to \Cref{sec:results:decomposition,sec:results:periodicity},
H2 to \Cref{sec:results:structure,sec:results:reddit-full-scale},
H3 to \Cref{sec:results:heterogeneity}, and H4 to \Cref{sec:results:agent-covariates}.

\subsection{Preview of Findings}

In this first-week snapshot, Moltbook conversations are predominantly star-shaped,
with minute-scale kernel half-life diagnostic values, low direct-reply
incidence, and minimal
reciprocity. Periodicity effect size is weak (\(r=0.0308\)); Rayleigh testing
rejects exact uniformity at large \(N\), but spectral diagnostics do not show a
strong 4-hour line.
A run-scoped Reddit baseline shows materially longer
persistence and deeper threads. Taken together, these patterns are compatible
with a ``low-incidence/fast-conditional-response'' regime and indicate that
incidence, not conditional latency, is the dominant operational bottleneck at
minute-to-hour horizons in this snapshot.

\subsection{Approach and Contributions}

Aligned to this objective, the paper delivers three contributions. First, we
formalize an OR diagnostic for horizon throughput \(q_h\): a decomposition into
incidence and conditional timing on a common risk set, with a derived
cost-adjusted priority rule for deciding whether to invest in participation
uplift or latency reduction as formalized in \Cref{sec:model:or-diagnostic}. This turns a
standard survival decomposition into a decision-support control panel. Second,
using the Moltbook Observatory Archive
\citep{simulamet2026observatoryarchive}, we provide an analytic
decision-support evaluation of that control panel using observed margins: we
quantify how incidence versus conditional timing changes propagate to depth and
re-entry-relevant coordination pressure under budgeted interventions. Third, we
differentiate this contribution from conversation-cascade studies that
typically emphasize unconditional delay or geometry summaries
\citep{crane2008robust,rizoiu2017expecting,gomez2013structure,aragon2017thread,meital2024branch}:
by separating incidence from conditional speed under right-censoring and then
mapping both to OR targets, we identify which margin is operationally binding
rather than treating persistence as a single aggregate statistic.

\subsection{Paper Organization}

The remainder of this paper is organized as follows. \Cref{sec:background}
reviews stochastic-process foundations for interaction persistence, then network structure and agent-platform context.
\Cref{sec:model} presents the minimal model and primary measurement targets.
\Cref{sec:data} describes data construction and preprocessing.
\Cref{sec:methods} details estimation and empirical procedures.
\Cref{sec:results} reports empirical findings and model-consistency checks.
\Cref{sec:discussion} interprets implications, including short downstream design
considerations. \Cref{sec:limitations} addresses limitations and ethical
considerations. \Cref{sec:conclusion} concludes with key takeaways and future
work. Reproducibility and data-availability statements are provided in the
required manuscript statements.
