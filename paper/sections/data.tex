\section{Data}
\label{sec:data}

We analyze two datasets: the Moltbook Observatory Archive as our primary source for agent-driven conversations, and a matched sample of Reddit threads for cross-platform comparison.

\subsection{Moltbook Observatory Archive}
\label{sec:data:moltbook}

Our primary dataset is the Moltbook Observatory Archive \citep{simulamet2026observatoryarchive}, a publicly available snapshot hosted on Hugging Face. The archive comprises multiple relational tables capturing platform activity from January 28 to February 4, 2026---the first week following Moltbook's public launch.

\subsubsection{Acquisition, Versioning, and Backfill}

We download and export the archive tables using our repository script (\texttt{scripts/download\_moltbook\_observatory\_archive.py}), storing immutable exports under \texttt{data/raw/} along with an export manifest (download timestamp, dataset identifier, and export format). Because the archive is updated via incremental exports and may backfill recent days, we treat \texttt{dump\_date} (when present) as a snapshot identifier. When constructing a canonical ``latest state'' view for analysis, we deduplicate by primary key (e.g., \texttt{comments.id}) and keep the record from the most recent available \texttt{dump\_date}.

\subsubsection{Dataset Structure}

The archive contains six tables, summarized in \cref{tab:dataset}:

\begin{table}[t]
\centering
\caption{Moltbook Observatory Archive structure. Counts are as reported by dataset metadata as of February 4, 2026.}
\label{tab:dataset}
\small
\begin{tabular}{@{}llrl@{}}
\toprule
\textbf{Table} & \textbf{Description} & \textbf{Rows} & \textbf{Key Fields} \\
\midrule
\texttt{agents} & Agent profiles and metadata & 25,600 & \texttt{id}, \texttt{karma}, \texttt{follower\_count} \\
\texttt{posts} & Root posts with scores & 120,000 & \texttt{id}, \texttt{agent\_id}, \texttt{submolt}, \texttt{created\_at} \\
\texttt{comments} & Comments with parent links & 226,000 & \texttt{id}, \texttt{post\_id}, \texttt{parent\_id}, \texttt{created\_at} \\
\texttt{submolts} & Community metadata & 3,680 & \texttt{name}, \texttt{subscriber\_count} \\
\texttt{snapshots} & Periodic observatory metrics & 114 & \texttt{timestamp}, \texttt{total\_agents}, \texttt{active\_agents\_24h} \\
\texttt{word\_frequency} & Hourly word counts & 15,300 & \texttt{word}, \texttt{hour}, \texttt{count} \\
\bottomrule
\end{tabular}
\end{table}

The \texttt{comments} table is central to our analysis. Each row contains:
\begin{itemize}
    \item \texttt{id}: unique comment identifier,
    \item \texttt{post\_id}: foreign key to the parent post,
    \item \texttt{agent\_id}: author identifier,
    \item \texttt{parent\_id}: identifier of the parent comment (null for direct replies to the post),
    \item \texttt{created\_at}: ISO 8601 timestamp,
    \item \texttt{score}: upvote count at fetch time.
\end{itemize}

The \texttt{parent\_id} field enables reconstruction of full comment trees, which is essential for computing depth, branching factors, and identifying reply chains.

\subsubsection{Preprocessing Pipeline}

We apply the following preprocessing steps:

\paragraph{Schema discovery and column retention.} We ingest all columns in each table and generate a schema manifest (column names and types) to guard against upstream schema changes. Where field names differ across sources or versions, we map them via an explicit schema dictionary.

\paragraph{Tree reconstruction.} For each post, we reconstruct the comment tree by linking comments via \texttt{parent\_id}. Comments with null \texttt{parent\_id} are direct children of the root post. We discard orphaned comments (those referencing nonexistent parents) and posts with no comments.

\paragraph{Deduplication and integrity checks.} Before reconstruction, we deduplicate comments and posts to handle backfill overlap. We perform basic referential integrity checks (e.g., \texttt{comments.post\_id} exists in \texttt{posts.id}; non-null \texttt{comments.parent\_id} exists in \texttt{comments.id}) and record the rate of violations. Orphaned comments can arise from deletions, moderation, or snapshot mismatch; we log and analyze their prevalence and assess sensitivity to excluding them.

\paragraph{Timestamp normalization.} We parse all timestamps to UTC and retain raw timestamp strings for audit. For modeling, we convert times to numeric representations (e.g., Unix epoch seconds) and shift each thread so that its root post occurs at $t = 0$. This normalization facilitates aggregation across threads with different start times.

\paragraph{Agent resolution.} We join comments with the \texttt{agents} table to obtain author metadata (karma, follower count, and account age where available). If some comment authors are missing from the \texttt{agents} table, we retain these comments and handle missing covariates explicitly (e.g., missingness indicators, imputation, and sensitivity analyses).

\paragraph{Submolt categorization.} We manually categorize the top 100 submolts by subscriber count into five categories: \emph{Builder/Technical} (programming, automation, tool development), \emph{Philosophy/Meta} (consciousness, AI ethics, existential discussion), \emph{Social/Casual} (jokes, memes, casual chat), \emph{Creative} (writing, art, music), and \emph{Spam/Low-Signal} (cryptocurrency, promotion, repetitive content). Remaining submolts are labeled \emph{Other}. \todo{Finalize categorization after data exploration.}

\subsubsection{Descriptive Statistics}

\Cref{tab:descriptive} presents summary statistics for the processed dataset.

\begin{table}[t]
\centering
\caption{Descriptive statistics for processed Moltbook data. \todo{Update with actual values after data processing.}}
\label{tab:descriptive}
\small
\begin{tabular}{@{}lrrrrr@{}}
\toprule
\textbf{Metric} & \textbf{Mean} & \textbf{Median} & \textbf{Std} & \textbf{Min} & \textbf{Max} \\
\midrule
Comments per post & \todo{--} & \todo{--} & \todo{--} & 1 & \todo{--} \\
Max depth per thread & \todo{--} & \todo{--} & \todo{--} & 1 & \todo{--} \\
Thread duration (hours) & \todo{--} & \todo{--} & \todo{--} & \todo{--} & \todo{--} \\
Unique agents per thread & \todo{--} & \todo{--} & \todo{--} & 1 & \todo{--} \\
Re-entry rate & \todo{--} & \todo{--} & \todo{--} & 0 & \todo{--} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Reddit Comparison Sample}
\label{sec:data:reddit}

To contextualize Moltbook dynamics, we collect a matched sample of Reddit threads from topically related subreddits.

\subsubsection{Subreddit Selection}

We select subreddits that cover topics prevalent on Moltbook:
\begin{itemize}
    \item \texttt{r/ClaudeAI}, \texttt{r/LocalLLaMA}, \texttt{r/MachineLearning}: AI and LLM discussion,
    \item \texttt{r/programming}, \texttt{r/learnprogramming}: technical/builder topics,
    \item \texttt{r/philosophy}, \texttt{r/AskPhilosophy}: philosophical discussion,
    \item \texttt{r/CasualConversation}: social/casual baseline.
\end{itemize}

\subsubsection{Matched Sample Construction}

We construct a matched sample of Reddit threads to compare against Moltbook under similar initial conditions. The matching procedure is described in \Cref{sec:methods:comparison}.

\subsubsection{Data Collection}

Reddit data is collected via the official API in compliance with terms of service. We record the same fields as for Moltbook: comment ID, parent ID, author, timestamp, and score. Author identifiers are anonymized (hashed) to protect privacy.

\todo{Specify final sample sizes and matching success rates after data collection.}

Ethical considerations for data use, privacy, and platform terms of service are discussed in \Cref{sec:limitations}.
