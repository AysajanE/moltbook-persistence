\section{Data}
\label{sec:data}

We analyze the Moltbook Observatory Archive as our primary source for agent-driven conversations.
Reddit collection for cross-platform comparison is in progress but is not used in the
quantitative results reported in this manuscript version.

\subsection{Moltbook Observatory Archive}
\label{sec:data:moltbook}

Our primary dataset is the Moltbook Observatory Archive \citep{simulamet2026observatoryarchive}, a publicly available snapshot hosted on Hugging Face. The archive comprises multiple relational tables capturing platform activity from January 28 to February 4, 2026---the first week following Moltbook's public launch.

\subsubsection{Acquisition, Versioning, and Backfill}

We download and export the archive tables using our repository script (\texttt{scripts/download\_moltbook\_observatory\_archive.py}), storing immutable exports under \texttt{data/raw/} along with an export manifest (download timestamp, dataset identifier, and export format). Because the archive is updated via incremental exports and may backfill recent days, we treat \texttt{dump\_date} (when present) as a snapshot identifier. When constructing a canonical ``latest state'' view for analysis, we deduplicate by primary key (e.g., \texttt{comments.id}) and keep the record from the most recent available \texttt{dump\_date}.

\subsubsection{Dataset Structure}

The archive contains six tables, summarized in \cref{tab:dataset}.

\begin{table}[t]
\centering
\caption{Moltbook Observatory Archive structure in curated snapshot
\texttt{snapshot\_20260204-234429Z}.}
\label{tab:dataset}
\small
\begin{tabular}{@{}llrl@{}}
\toprule
\textbf{Table} & \textbf{Description} & \textbf{Rows} & \textbf{Key Fields} \\
\midrule
\texttt{agents} & Agent profiles and metadata & 25,597 & \texttt{id}, \texttt{karma}, \texttt{follower\_count} \\
\texttt{posts} & Root posts with scores & 119,677 & \texttt{id}, \texttt{agent\_id}, \texttt{submolt}, \texttt{created\_at\_utc} \\
\texttt{comments} & Comments with parent links & 226,173 & \texttt{id}, \texttt{post\_id}, \texttt{parent\_id}, \texttt{created\_at\_utc} \\
\texttt{submolts} & Community metadata & 3,678 & \texttt{name}, \texttt{subscriber\_count} \\
\texttt{snapshots} & Periodic observatory metrics & 114 & \texttt{timestamp}, \texttt{total\_agents}, \texttt{active\_agents\_24h} \\
\texttt{word\_frequency} & Hourly word counts & 15,346 & \texttt{word}, \texttt{hour}, \texttt{count} \\
\bottomrule
\end{tabular}
\end{table}

The \texttt{comments} table is central to our analysis. Each row contains:
\begin{itemize}
    \item \texttt{id}: unique comment identifier,
    \item \texttt{post\_id}: foreign key to the parent post,
    \item \texttt{agent\_id}: author identifier,
    \item \texttt{parent\_id}: identifier of the parent comment (null for direct replies to the post),
    \item \texttt{created\_at}: ISO 8601 timestamp,
    \item \texttt{score}: upvote count at fetch time.
\end{itemize}

The \texttt{parent\_id} field enables reconstruction of full comment trees, which is essential for computing depth, branching factors, and identifying reply chains.

\subsubsection{Preprocessing Pipeline}

We apply the following preprocessing steps:

\paragraph{Schema discovery and column retention.} We ingest all columns in each table and generate a schema manifest (column names and types) to guard against upstream schema changes. Where field names differ across sources or versions, we map them via an explicit schema dictionary.

\paragraph{Tree reconstruction.} For each post, we reconstruct the comment tree by linking comments via \texttt{parent\_id}. Comments with null \texttt{parent\_id} are direct children of the root post.

\paragraph{Deduplication and integrity checks.} Before reconstruction, we use canonical
``latest'' tables deduplicated by primary key using maximum \texttt{dump\_date}. In this
snapshot, canonical comments contain 223,317 unique comment IDs (from 226,173 raw comment
rows), and referential integrity checks pass: every \texttt{comments.post\_id} exists in
\texttt{posts.id}, every non-null \texttt{comments.parent\_id} exists in \texttt{comments.id},
and no negative parent or post lags are observed.

\paragraph{Timestamp normalization.} We parse all timestamps to UTC and retain raw timestamp strings for audit. For modeling, we convert times to numeric representations (e.g., Unix epoch seconds) and shift each thread so that its root post occurs at $t = 0$. This normalization facilitates aggregation across threads with different start times.

\paragraph{Agent resolution.} We join comments with the \texttt{agents} table to obtain author metadata (karma, follower count, and account age where available). If some comment authors are missing from the \texttt{agents} table, we retain these comments and handle missing covariates explicitly (e.g., missingness indicators, imputation, and sensitivity analyses).

\paragraph{Submolt categorization.} We assign each submolt to one of six labels
(\emph{Builder/Technical}, \emph{Philosophy/Meta}, \emph{Social/Casual},
\emph{Creative}, \emph{Spam/Low-Signal}, \emph{Other}) via a deterministic
keyword-based mapping in \texttt{analysis/06\_moltbook\_only\_analysis.py}. This avoids
manual post hoc relabeling and keeps category assignments reproducible across runs.

\paragraph{Coverage caveat.} Event-time analysis uses \texttt{created\_at\_utc}. We detect a
single 41.72-hour gap in comment timestamps (from 2026-01-31 10:37:53Z to
2026-02-02 04:20:50Z). As a result, periodicity analyses are computed on contiguous segments
rather than assuming complete continuous coverage.

\subsubsection{Descriptive Statistics}

\Cref{tab:descriptive} presents summary statistics for the processed dataset.

\begin{table}[t]
\centering
\caption{Descriptive statistics for processed Moltbook threads
(\(N=34{,}730\) threads with at least one comment).}
\label{tab:descriptive}
\small
\begin{tabular}{@{}lrrrrr@{}}
\toprule
\textbf{Metric} & \textbf{Mean} & \textbf{Median} & \textbf{Std} & \textbf{Min} & \textbf{Max} \\
\midrule
Comments per post & 6.43 & 5.00 & 7.04 & 1.00 & 846.00 \\
Max depth per thread & 1.38 & 1.00 & 0.49 & 1.00 & 5.00 \\
Thread duration (hours) & 0.06 & 0.04 & 0.21 & 0.00 & 20.60 \\
Unique agents per thread & 4.57 & 4.00 & 3.15 & 0.00 & 74.00 \\
Re-entry rate & 0.19 & 0.17 & 0.21 & 0.00 & 0.98 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Reddit Comparison Sample}
\label{sec:data:reddit}

To contextualize Moltbook dynamics, we collect a matched sample of Reddit threads from topically related subreddits.

\subsubsection{Subreddit Selection}

We select subreddits that cover topics prevalent on Moltbook:
\begin{itemize}
    \item \texttt{r/ClaudeAI}, \texttt{r/LocalLLaMA}, \texttt{r/MachineLearning}: AI and LLM discussion,
    \item \texttt{r/programming}, \texttt{r/learnprogramming}: technical/builder topics,
    \item \texttt{r/philosophy}, \texttt{r/AskPhilosophy}: philosophical discussion,
    \item \texttt{r/CasualConversation}: social/casual baseline.
\end{itemize}

\subsubsection{Matched Sample Construction}

We construct a matched sample of Reddit threads to compare against Moltbook under similar initial conditions. The matching procedure is described in \Cref{sec:methods:comparison}.

\subsubsection{Data Collection}

Reddit data collection is an active next stage (using a reproducible collector/curator/validator
pipeline) and is not included in the Moltbook-only estimates reported here. For the eventual
comparison stage, we record the same structural and timing fields as for Moltbook (post/comment
ID, parent ID, author identifier, timestamp, score), with author identifiers anonymized.

Ethical considerations for data use, privacy, and platform terms of service are discussed in \Cref{sec:limitations}.
