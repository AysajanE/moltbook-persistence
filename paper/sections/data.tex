\section{Data}
\label{sec:data}

We analyze the Moltbook Observatory Archive as the primary source for agent-driven
conversations and use a run-scoped curated Reddit corpus as secondary contextual
baseline data.

\subsection{Moltbook Observatory Archive}
\label{sec:data:moltbook}

Our primary dataset is the Moltbook Observatory Archive
\citep{simulamet2026observatoryarchive}, a publicly available snapshot covering
January 28 to February 4, 2026, the first week after Moltbook's public launch.

Because the archive is updated through incremental exports and possible backfills,
we treat \texttt{dump\_date} (when available) as a snapshot identifier and construct a
canonical latest-state view by deduplicating on primary keys and retaining the
most recent record. The archive contains six relational tables (\texttt{agents}, \texttt{posts},
\texttt{comments}, \texttt{submolts}, \texttt{snapshots}, \texttt{word\_frequency}).

The \texttt{comments} table is central to our analysis. Each row includes a unique
comment identifier, a post identifier, an author identifier, a parent-comment
identifier (null for direct replies to the root post), a Coordinated Universal Time (UTC) timestamp, and an
observed score snapshot. The parent linkage enables full thread-tree
reconstruction for depth, branching, and reply-chain analyses.

Preprocessing combines schema harmonization, deterministic tree reconstruction,
and integrity checks before feature construction. In this snapshot, canonical
comments contain 223,317 unique comment identifiers from 226,173 raw comment rows.
Referential checks pass: every \texttt{comments.post\_id} maps to a valid post,
every non-null \texttt{comments.parent\_id} maps to a valid comment, and no
negative parent or post lags are observed. Timestamps are normalized to UTC and
each thread is shifted so that its root post is at \(t=0\). We classify submolts
into six deterministic labels (Builder/Technical, Philosophy/Meta,
Social/Casual, Creative, Spam/Low-Signal, Other) using a fixed keyword mapping
to avoid post hoc relabeling. Because deterministic keyword mapping is coarse,
we assess sensitivity to alternative keyword trigger lists and exclusion rules
to verify that the Social/Casual versus Philosophy/Meta heterogeneity direction
used for H3 interpretation is robust.

Author identifiers are nearly complete but not perfect. In this snapshot,
906 of 223,317 comments (0.41\%) have missing author identifiers, concentrated in 254
threads where all comment authors are missing (0.73\% of threads). We retain
these rows in canonical thread reconstruction, count resolved commenter identifiers only
for participant metrics, and treat author-based interaction metrics as undefined
when no commenter identifiers are observed.

Event-time analyses use UTC timestamps. The canonical timeline contains a
41.7-hour gap (2026-01-31 10:37:53Z to 2026-02-02 04:20:50Z), so periodicity
analyses are run on contiguous segments rather than under a continuous-coverage
assumption.
Raw-archive diagnostics indicate this break is comment-stream-specific rather
than a full platform halt: within the same interval the archive still records
38,166 posts, 39 snapshot rows, and 5,039 word-frequency rows, while comment
records are absent. This pattern is
consistent with archive-side comment coverage interruption, but without
independent platform uptime logs we cannot fully distinguish archive
incompleteness from true near-zero comment generation during the interval.

Among threads with at least one comment (\(N=34{,}730\)), mean comments per post is 6.43 and mean maximum depth is 1.38.

\subsection{Run-Scoped Curated Reddit Corpus}
\label{sec:data:reddit}

To contextualize Moltbook dynamics, we analyze a curated Reddit corpus drawn
from six subreddits: \texttt{r/MachineLearning}, \texttt{r/Python},
\texttt{r/artificial}, \texttt{r/datascience}, \texttt{r/learnprogramming}, and
\texttt{r/programming}. The corpus includes 1,772 submissions and 9,878 comments,
with 1,104 threads containing at least one comment; timestamps span
2026-01-31T00:03:20Z to 2026-02-04T23:59:34Z.

Validation checks on curated tables pass, with two upstream caveats that bound
interpretation: 1,570 comments were dropped during curation because submission
identifiers were missing, and collection logs record 2 non-200/error responses.

This Reddit corpus is used as descriptive baseline context: we estimate
Reddit-side geometry, survival, and periodicity metrics using the same
estimators as for Moltbook in \Cref{sec:results:reddit-full-scale}. Ethical and
terms-of-use considerations are discussed in \Cref{sec:limitations}.
