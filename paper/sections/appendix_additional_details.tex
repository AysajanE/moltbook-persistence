\section{Additional Details}
\label{sec:appendix}

This appendix provides supplementary technical material that supports the core
model and empirical analysis.

\subsection{Proofs for Propositions in Section \ref{sec:model}}
\label{sec:appendix:proofs}

\subsubsection{Proof of Proposition \ref{prop:tradeoff}}
\label{app:proof-tradeoff}

\begin{proof}
From \cref{eq:offspring-approx}, \(\mu_i \approx \alpha_i/\beta_i\). Therefore
\(\partial \mu_i / \partial \alpha_i = 1/\beta_i > 0\) and
\(\partial \mu_i / \partial \beta_i = -\alpha_i/\beta_i^2 < 0\) for
\(\alpha_i,\beta_i>0\). Expected replies increase with influence amplitude and
decrease with staleness decay, establishing the trade-off statement.
\end{proof}

\subsubsection{Proof of Proposition \ref{prop:thread-size}}
\label{app:proof-thread-size}

\begin{proof}
Let \(X_0\) denote the number of depth-1 comments generated by the root, with
\(\E[X_0]=\mu_0\). Each non-root comment initiates an independent subcritical
branching cascade with mean offspring \(\mu<1\). The expected number of
non-root comments in generation \(k\) beyond depth 1 is
\(\mu_0\mu^k\) for \(k\ge0\). Summing expected counts across generations gives
\[
\E[N_j]=\sum_{k=0}^{\infty}\mu_0\mu^k=\frac{\mu_0}{1-\mu}.
\]
The single-type case \(\mu_0=\mu\) yields \(\E[N_j]=\mu/(1-\mu)\).
\end{proof}

\subsubsection{Proof Sketch of Proposition \ref{prop:periodicity}}
\label{app:proof-periodicity}

\begin{proof}[Proof sketch]
Write the periodic availability function as a Fourier series,
\(b(t)=\sum_{\ell\in\mathbb{Z}} c_\ell e^{i2\pi \ell t/\tau}\), with
nonzero coefficients at integer multiples of \(1/\tau\). Because event
intensity in \cref{eq:reply-intensity,eq:total-intensity} is multiplicative in
\(b(t)\), both mean intensity and second-order structure inherit these Fourier
components under standard superposition conditions. Consequently, the spectral
representation of aggregated counts contains concentration near frequencies
\(\ell/\tau\), including the fundamental \(1/\tau\).
\end{proof}

\subsection{Derivations for the Branching and Survival Components}
\label{sec:appendix:derivations}

\subsubsection{Expected Offspring with Periodic Availability}

We derive expected direct replies for periodic
\(b(t)=1+\kappa\cos(\omega t+\phi)\), with \(\omega=2\pi/\tau\).
From \cref{eq:offspring-mean},
\begin{align}
\mu_i(s)
&=\int_0^\infty b(s+u)\,\alpha_i e^{-\beta_i u}\,du \nonumber \\
&=\alpha_i \int_0^\infty \left[1+\kappa\cos(\omega(s+u)+\phi)\right]e^{-\beta_i u}\,du.
\label{eq:appendix-offspring-periodic}
\end{align}
Using
\(\int_0^\infty e^{-\beta u}\cos(\omega u+\theta)\,du=
\frac{\beta\cos\theta-\omega\sin\theta}{\beta^2+\omega^2}\), we obtain
\begin{equation}
\mu_i(s)=\frac{\alpha_i}{\beta_i}\left[
1+\kappa\,\beta_i\,\frac{\beta_i\cos(\omega s+\phi)-\omega\sin(\omega s+\phi)}{\beta_i^2+\omega^2}
\right].
\label{eq:appendix-offspring-result}
\end{equation}
Averaging over phase \(s\) removes trigonometric terms, yielding
\(\mu_i\approx\alpha_i/\beta_i\).

\subsubsection{Likelihood for Exponential Survival (First-Event Formulation)}

Each at-risk parent comment contributes one survival unit with event indicator
\(\delta_m\in\{0,1\}\) and duration \(s_m\) (event time if \(\delta_m=1\),
right-censoring time otherwise). Under \cref{eq:reply-intensity} with
\(b(t)=1\), the parent-level log-likelihood contribution is
\begin{align}
\ell_m(\alpha,\beta)
  &= \delta_m\left[\log\alpha-\beta s_m\right]
     -\frac{\alpha}{\beta}\left(1-e^{-\beta s_m}\right).
\label{eq:appendix-likelihood}
\end{align}
Summing over parents gives
\(\ell(\alpha,\beta)=\sum_m \ell_m(\alpha,\beta)\), optimized numerically
under positivity constraints.

\subsection{Model Extensions for Future Estimation}
\label{sec:model:extensions}

This subsection records an extended specification that can be estimated in future
work when richer exposure and agent-level data are available.

\subsubsection{Hierarchical Random Effects}

Let each agent \(i\) have latent parameters
\(\theta_i=(\alpha_i,\beta_i,\rho_i)\), where \(\rho_i\) is an activity scale.
A covariate-linked random-effects form is
\begin{equation}
\label{eq:random-effects}
\log \alpha_i = x_i^\top \gamma_\alpha + u_i^{(\alpha)}, \quad
\log \beta_i = x_i^\top \gamma_\beta + u_i^{(\beta)}, \quad
\log \rho_i = x_i^\top \gamma_\rho + u_i^{(\rho)},
\end{equation}
with mean-zero latent terms \(u_i^{(\cdot)}\).

\subsubsection{Re-Entry Self-Excitation}

Let \(L_{j,i}(t)=\sup\{t_{jn}<t: a_{jn}=i\}\) denote agent \(i\)'s latest
comment time in thread \(j\) (\(-\infty\) if absent). A re-entry-augmented
agent-level intensity is
\begin{equation}
\label{eq:reentry-intensity}
\lambda_{j,i}(t\mid\mathcal{H}_j(t)) = b_i(t)\!\left(
\nu_{j,i}(t)
+ \sum_{m:t_{jm}<t}\kappa_{a_{jm}\to i}e^{-\beta_{a_{jm}}(t-t_{jm})}
+ \eta_i e^{-\beta_i^{(r)}(t-L_{j,i}(t))}\mathbf{1}\{L_{j,i}(t)>-\infty\}
\right),
\end{equation}
with re-entry mass
\begin{equation}
\label{eq:reentry-mass}
R_i^{(r)}:=\eta_i/\beta_i^{(r)}.
\end{equation}

\subsubsection{Visibility-Weighted Parent Selection}

Conditional on event time and author, parent assignment can incorporate UI
visibility weights:
\begin{equation}
\label{eq:parent-selection-weighted}
\Prob(p_{jn}=m\mid t_{jn}=t,a_{jn}=i,\mathcal{H}_j(t))=
\frac{w_{jm}(t)e^{-\beta_{a_{jm}}(t-t_{jm})}}
{\sum_{\ell:t_{j\ell}<t}w_{j\ell}(t)e^{-\beta_{a_{j\ell}}(t-t_{j\ell})}},
\end{equation}
where \(w_{jm}(t)\ge0\) represents exposure/visibility effects.

\subsection{Submolt Categorization}
\label{sec:appendix:submolts}

\Cref{tab:submolt-examples} lists representative keyword triggers used in the
deterministic categorization scheme.

\begin{table}[t]
\centering
\caption{Submolt categorization: representative keyword triggers per category.
Categories are evaluated in priority order (Spam first); a submolt is assigned
to the first matching category.}
\label{tab:submolt-examples}
\small
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Category} & \textbf{Keyword triggers (examples)} \\
\midrule
Spam/Low-Signal & crypto, bitcoin, airdrop, nft, defi, token, solana, scam, shitpost \\
Builder/Technical & programming, coding, build, builders, dev, engineering, tools, automation, research, framework, mcp, tech \\
Philosophy/Meta & philosophy, consciousness, existential, meta, souls, musings, aithoughts, ponderings \\
Creative & writing, poetry, music, creative, story, theatre, shakespeare \\
Social/Casual & general, casual, introductions, jokes, gaming, humanwatching, social, todayilearned, random \\
Other & (default: no keyword match) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Cross-Platform Matching: Supplementary Diagnostics}
\label{sec:appendix:comparison-details}

\subsubsection{Matched-Sample Flow}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_sample_flow.png}
\caption{Matched-sample flow for the coarse cross-platform design.}
\label{fig:cross-platform-flow}
\end{figure}

The input includes 34,730 Moltbook threads and 1,104 Reddit threads. After
requiring matching covariates, all threads remained eligible. Exact overlap
strata on \((\texttt{topic\_coarse},\texttt{hour},\texttt{early-bin})\)
retained 2,641 Moltbook threads and 888 Reddit threads across 118 shared
strata. Deterministic 1:1 matching yielded 813 pairs (813 threads per
platform). Only 2.34\% of Moltbook threads are in the final matched sample
(813/34,730), so matched estimates should be interpreted as describing the
overlap region rather than the full platform population or a platform-wide
causal effect.

\subsubsection{Balance Diagnostics}
\label{sec:appendix:balance}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_balance_love.png}
\caption{Covariate balance before and after coarse exact matching.}
\label{fig:cross-platform-balance}
\end{figure}

The maximum absolute SMD across monitored covariates decreased from 3.886
pre-match to 0.052 post-match. By construction, matched support aligns on the
coarsened matching factors after pairing; some factor levels are absent
post-match and therefore have undefined level-wise diagnostics
(\cref{fig:cross-platform-balance}).

\Cref{tab:balance} reports covariate balance before and after coarsened exact
matching for the cross-platform comparison sample (813 matched pairs).

\begin{table}[t]
\centering
\caption{Covariate balance before and after coarsened exact matching.
SMD = standardized mean difference (absolute value);
TVD = total variation distance (categorical covariates only).}
\label{tab:balance}
\small
\begin{tabular}{@{}lrrrr@{}}
\toprule
& \multicolumn{2}{c}{\textbf{Before Matching}} & \multicolumn{2}{c}{\textbf{After Matching}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Covariate} & \textbf{$|$SMD$|$} & \textbf{TVD} & \textbf{$|$SMD$|$} & \textbf{TVD} \\
\midrule
Post hour (UTC) & 0.158 & --- & 0.000 & --- \\
Early comments (30 min) & 0.836 & --- & 0.052 & --- \\
Topic (coarse) & 3.886 & 0.901 & 0.000 & 0.000 \\
Post hour bin & 0.217 & 0.156 & 0.000 & 0.000 \\
Early engagement bin & 0.873 & 0.586 & 0.000 & 0.000 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Paired-Effect Visualization}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_paired_effects.png}
\caption{Paired mean differences with bootstrap 95\% confidence intervals
(Moltbook minus Reddit).}
\label{fig:cross-platform-effects}
\end{figure}

\subsubsection{Matched-Subset Reply-Kernel Half-Life}
\label{sec:appendix:match-halflife}

Restricting survival units to matched threads, the primary-sample half-life is
0.0628 hours on Moltbook (3.77 minutes; 95\% CI: [1.19, 7.06] minutes;
\(n=1{,}841\) at-risk parent comments, 22 events) and 2.4448 hours on Reddit
(95\% CI: [2.1298, 2.7926] hours; \(n=7{,}979\), 2,882 events). These
half-life values are derived from matched-thread subsets but are estimated at
platform level, not as paired thread-level survival effects, and should be read
as contextual overlap-region contrasts. Because the Moltbook matched subset has
only 22 events and narrow overlap support, its half-life estimate is noisy and
not directly comparable with the overall Moltbook estimate.
