\section{Additional Details}
\label{sec:appendix}

This appendix provides supplementary technical material that supports the core
model and empirical analysis.

\subsection{Proofs for Propositions in Section \ref{sec:model}}
\label{sec:appendix:proofs}

\subsubsection{Proof of Proposition \ref{prop:tradeoff}}
\label{app:proof-tradeoff}

\begin{proof}
For fixed \(s\), use the exact mean-offspring expression
\[
\mu_i(s)=\int_0^\infty b(s+u)\,\alpha_i e^{-\beta_i u}\,du,
\]
with \(b(\cdot)\ge0\). Differentiating under the integral sign gives
\[
\frac{\partial \mu_i(s)}{\partial \alpha_i}
=\int_0^\infty b(s+u)e^{-\beta_i u}\,du>0,
\]
since the integrand is nonnegative and nonzero for nontrivial activity, and
\[
\frac{\partial \mu_i(s)}{\partial \beta_i}
=\int_0^\infty b(s+u)\,\alpha_i(-u)e^{-\beta_i u}\,du<0,
\]
because \(\alpha_i>0\), \(u>0\) on \((0,\infty)\), and \(b(s+u)\ge0\).
Hence \(\mu_i(s)\) is strictly increasing in \(\alpha_i\) and strictly
decreasing in \(\beta_i\), proving the claim exactly (without using
\(\mu_i\approx\alpha_i/\beta_i\)).
\end{proof}

\subsubsection{Proof of Proposition \ref{prop:thread-size}}
\label{app:proof-thread-size}

\begin{proof}
Let \(X_0\) denote the number of depth-1 comments generated by the root, with
\(\E[X_0]=\mu_0\). Each non-root comment initiates an independent subcritical
branching cascade with mean offspring \(\mu<1\). The expected number of
non-root comments in generation \(k\) beyond depth 1 is
\(\mu_0\mu^k\) for \(k\ge0\). Summing expected counts across generations gives
\[
\E[N_j]=\sum_{k=0}^{\infty}\mu_0\mu^k=\frac{\mu_0}{1-\mu}.
\]
The single-type case \(\mu_0=\mu\) yields \(\E[N_j]=\mu/(1-\mu)\).
\end{proof}

\subsubsection{Proof of Proposition \ref{prop:periodicity}}
\label{app:proof-periodicity}

\begin{proof}
Under the proposition assumptions, mean intensity is
\[
m(t):=\E[\lambda(t)]=\E[b(t)g(t)]=b(t)\E[g(t)].
\]
If \(\E[g(t)]\) is \(\tau\)-periodic (including the approximately constant
case on the \(\tau\)-scale), then \(m(t)\) is \(\tau\)-periodic. For binned
counts \(C_r:=N((r\Delta,(r+1)\Delta])\),
\[
\E[C_r]=\int_{r\Delta}^{(r+1)\Delta} m(s)\,ds,
\]
so the discrete-time mean sequence inherits the same periodic structure
(exactly when \(\tau/\Delta\) is commensurate, otherwise with nearby discrete
frequency concentration). A periodic mean has Fourier mass at harmonics
\(\ell/\tau\), \(\ell\in\mathbb{Z}\), and therefore contributes line-like
components to expected periodogram/PSD estimates of \(C_r\). In finite windows,
windowing and binning spread this mass across nearby frequencies, so empirical
peaks appear near \(\ell/\tau\) rather than as exact lines (spectral leakage).
\end{proof}

\subsection{Derivations for the Branching and Survival Components}
\label{sec:appendix:derivations}

\subsubsection{Expected Offspring with Periodic Availability}

We derive expected direct replies for periodic
\(b(t)=1+\kappa\cos(\omega t+\phi)\), with \(\omega=2\pi/\tau\).
From \cref{eq:offspring-mean},
\begin{align}
\mu_i(s)
&=\int_0^\infty b(s+u)\,\alpha_i e^{-\beta_i u}\,du \nonumber \\
&=\alpha_i \int_0^\infty \left[1+\kappa\cos(\omega(s+u)+\phi)\right]e^{-\beta_i u}\,du.
\label{eq:appendix-offspring-periodic}
\end{align}
Using
\(\int_0^\infty e^{-\beta u}\cos(\omega u+\theta)\,du=
\frac{\beta\cos\theta-\omega\sin\theta}{\beta^2+\omega^2}\), we obtain
\begin{equation}
\mu_i(s)=\frac{\alpha_i}{\beta_i}\left[
1+\kappa\,\beta_i\,\frac{\beta_i\cos(\omega s+\phi)-\omega\sin(\omega s+\phi)}{\beta_i^2+\omega^2}
\right].
\label{eq:appendix-offspring-result}
\end{equation}
Averaging over phase \(s\) removes trigonometric terms, yielding
\(\mu_i\approx\alpha_i/\beta_i\).

\subsubsection{Likelihood for Exponential Survival (First-Event Formulation)}

Each at-risk comment (candidate parent) contributes one survival unit with event indicator
\(\delta_m\in\{0,1\}\) and duration \(s_m\) (event time if \(\delta_m=1\),
right-censoring time otherwise). Under \cref{eq:reply-intensity} with
\(b(t)=1\), the parent-level log-likelihood contribution is
\begin{align}
\ell_m(\alpha,\beta)
  &= \delta_m\left[\log\alpha-\beta s_m\right]
     -\frac{\alpha}{\beta}\left(1-e^{-\beta s_m}\right).
\label{eq:appendix-likelihood}
\end{align}
Summing over parents gives
\(\ell(\alpha,\beta)=\sum_m \ell_m(\alpha,\beta)\), optimized numerically
under positivity constraints.

Under the same hazard \(\lambda(s)=\alpha e^{-\beta s}\), the exact
first-reply density conditional on at least one reply is
\begin{equation}
\label{eq:appendix-conditional-density}
f(s\mid \text{event})
=\frac{\alpha e^{-\beta s}\exp\!\left[-(\alpha/\beta)(1-e^{-\beta s})\right]}
{1-\exp(-\alpha/\beta)}, \qquad s\ge0.
\end{equation}
When \(\alpha/\beta\ll1\), this conditional law is well approximated by
\(\mathrm{Exponential}(\beta)\), which is the regime used for the model-check
interpretation in the main text.

\subsection{Operational Estimation Settings (Methods Details)}
\label{sec:appendix:operational-details}

This subsection records manuscript-level operational settings referenced from
\Cref{sec:methods}.

\subsubsection{Coverage and Candidate-Parent Rules}

For survival estimation, each non-root comment is treated as one at-risk
candidate parent unit. First-reply durations are right-censored at the observed
coverage boundary. No replies are imputed across the canonical 41.7-hour
timeline gap, and half-life analyses use a 4-hour end-of-window censor boundary
exclusion. Missing-author-ID handling is deterministic: participant counts use
observed commenter IDs only; re-entry denominators include comments with known
commenter IDs only; reciprocity uses edges with known source and parent IDs;
author-based thread metrics are left undefined when no commenter IDs are
observed.

\subsubsection{Periodicity Preprocessing and Test Knobs}

Periodicity analysis splits activity timelines at timestamp gaps greater than 6
hours and retains the longest contiguous segment. The primary bin width is
15 minutes (\(\Delta=0.25\) hours), with robustness repeats at 5, 15, and
30 minutes on the same contiguous segment. The transformed series is
\[
Y_t=\log(1+C_t)-\operatorname{MA}_{24\mathrm{h}}(t),
\]
where \(\operatorname{MA}_{24\mathrm{h}}\) is a centered 24-hour rolling mean
(96 bins at 15-minute resolution) with truncated edge windows
(\texttt{min\_periods=1}), followed by mean-centering. Welch PSD settings use a
Hann window, \texttt{nperseg}\(=\min(128,T)\),
\texttt{noverlap}\(=\min(64,\lfloor T/2\rfloor)\), and constant detrending
within segments.

AR(1) null calibration is performed by Monte Carlo simulation with
\(B=2{,}000\) synthetic series in the pinned runs.

\subsubsection{Bootstrap Mechanics}

Confidence intervals are computed with cluster bootstrap resampling at the
thread level for Moltbook-only and Reddit-only analyses. In the pinned runs
(\Cref{sec:reproducibility}), thread-cluster replicates are
\texttt{bootstrap\_reps=400}. For cross-platform matched analyses, paired
outcome differences use matched-pair bootstrap resampling with
\texttt{bootstrap\_reps=1000}, and matched-subset half-life intervals use
thread-cluster resampling with \texttt{half\_life\_bootstrap\_reps=400}.

\subsubsection{Matching Mechanics}

Coarsened exact matching uses three controls: first-30-minute action volume
(bins \(\{0, 1\text{--}2, 3\text{--}5, 6\text{--}10, 11+\}\)), deterministic
coarse topic map (\texttt{tech}/\texttt{meta}/\texttt{general}/\texttt{spam}),
and exact UTC posting hour \((0,\ldots,23)\). Within each shared stratum,
threads are sorted deterministically and paired one-to-one up to
\(\min(n_M,n_R)\). Supplementary overlap flow and balance diagnostics are
reported in \Cref{sec:appendix:comparison-details}.

\subsection{Model Extensions for Future Estimation}
\label{sec:model:extensions}

This subsection records an extended specification that can be estimated in future
work when richer exposure and agent-level data are available.

\subsubsection{Hierarchical Random Effects}

Let each agent \(i\) have latent parameters
\(\theta_i=(\alpha_i,\beta_i,\rho_i)\), where \(\rho_i\) is an activity scale.
A covariate-linked random-effects form is
\begin{equation}
\label{eq:random-effects}
\log \alpha_i = x_i^\top \gamma_\alpha + u_i^{(\alpha)}, \quad
\log \beta_i = x_i^\top \gamma_\beta + u_i^{(\beta)}, \quad
\log \rho_i = x_i^\top \gamma_\rho + u_i^{(\rho)},
\end{equation}
with mean-zero latent terms \(u_i^{(\cdot)}\).

\subsubsection{Re-Entry Self-Excitation}

Let \(L_{j,i}(t)=\sup\{t_{jn}<t: a_{jn}=i\}\) denote agent \(i\)'s latest
comment time in thread \(j\) (\(-\infty\) if absent). A re-entry-augmented
agent-level intensity is
\begin{equation}
\label{eq:reentry-intensity}
\lambda_{j,i}(t\mid\mathcal{H}_j(t)) = b_i(t)\!\left(
\nu_{j,i}(t)
+ \sum_{m:t_{jm}<t}\kappa_{a_{jm}\to i}e^{-\beta_{a_{jm}}(t-t_{jm})}
+ \eta_i e^{-\beta_i^{(r)}(t-L_{j,i}(t))}\mathbf{1}\{L_{j,i}(t)>-\infty\}
\right),
\end{equation}
with re-entry mass
\begin{equation}
\label{eq:reentry-mass}
R_i^{(r)}:=\eta_i/\beta_i^{(r)}.
\end{equation}

\subsubsection{Visibility-Weighted Parent Selection}

Conditional on event time and author, parent assignment can incorporate UI
visibility weights:
\begin{equation}
\label{eq:parent-selection-weighted}
\Prob(p_{jn}=m\mid t_{jn}=t,a_{jn}=i,\mathcal{H}_j(t))=
\frac{w_{jm}(t)e^{-\beta_{a_{jm}}(t-t_{jm})}}
{\sum_{\ell:t_{j\ell}<t}w_{j\ell}(t)e^{-\beta_{a_{j\ell}}(t-t_{j\ell})}},
\end{equation}
where \(w_{jm}(t)\ge0\) represents exposure/visibility effects.

\subsection{Submolt Categorization}
\label{sec:appendix:submolts}

\Cref{tab:submolt-examples} lists representative keyword triggers used in the
deterministic categorization scheme.

\begin{table}[t]
\centering
\caption{Submolt categorization: representative keyword triggers per category.
Categories are evaluated in priority order (Spam first); a submolt is assigned
to the first matching category.}
\label{tab:submolt-examples}
\small
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Category} & \textbf{Keyword triggers (examples)} \\
\midrule
Spam/Low-Signal & crypto, bitcoin, airdrop, nft, defi, token, solana, scam, shitpost \\
Builder/Technical & programming, coding, build, builders, dev, engineering, tools, automation, research, framework, mcp, tech \\
Philosophy/Meta & philosophy, consciousness, existential, meta, souls, musings, aithoughts, ponderings \\
Creative & writing, poetry, music, creative, story, theatre, shakespeare \\
Social/Casual & general, casual, introductions, jokes, gaming, humanwatching, social, todayilearned, random \\
Other & (default: no keyword match) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Periodicity Robustness Details}
\label{sec:appendix:periodicity-robustness}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/periodicity_bin_robustness_moltbook.png}
\caption{Bin-width robustness for Moltbook periodicity tests (5, 15, 30 minutes).}
\label{fig:periodicity-bin-robustness}
\end{figure}

\subsection{Reddit Baseline Supplementary Diagnostics}
\label{sec:appendix:reddit-details}

\subsubsection{Geometry, Branching, and Re-Entry}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/depth_distribution_reddit.png}
\caption{Distribution of maximum thread depth \(D_j\) over Reddit threads with
at least one comment (\(N=1{,}104\)); root submissions are fixed at depth 0, and
in this sample \(D_j\) therefore coincides with maximum comment depth.}
\label{fig:depth-distribution-reddit}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/branching_by_depth_reddit.png}
\caption{Mean direct-children count by node depth for Reddit threads with at
least one comment; depth 0 is the root submission and depths \(\geq 1\) are
non-root comments.}
\label{fig:branching-by-depth-reddit}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/reentry_distribution_reddit.png}
\caption{Distribution of thread-level re-entry rate
\(\mathrm{RE}_j^{\mathrm{comment}}\) for Reddit threads with at least one
comment; root-submission authorship is excluded unless the root author later
appears in the comment sequence.}
\label{fig:reentry-distribution-reddit}
\end{figure}

Conversation geometry is materially deeper than a pure star regime but still
root-concentrated. Mean maximum depth per thread is 2.17 (median maximum depth
1), \(\Prob(D \ge 5)=11.32\%\), \(\Prob(D \ge 10)=1.54\%\), mean branching
factor is 4.31 at depth 0 and 0.45 at depth 1, and re-entry has mean 0.094 and
median 0.

\subsubsection{Reply-Kernel Half-Life}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/survival_curve_reddit.png}
\caption{Kaplan--Meier survival curve and fitted exponential-kernel hazard model for the Reddit run.}
\label{fig:survival-curve-reddit}
\end{figure}

The primary survival sample includes 9,547 at-risk comments (candidate parents)
(3,456 events; 6,091 censored), after excluding 329 parents within the 4-hour
right-boundary window. The exponential estimate gives a reply-kernel half-life
of 2.61 hours (95\% CI: [2.29, 2.95]). A no-boundary sensitivity estimate is
similar at 2.58 hours. The observed direct-reply probability is 36.20\%
(3,456/9,547), with implied eventual probability 38.70\% under the fitted
exponential-kernel hazard model.

\subsubsection{Periodicity}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/psd_reddit.png}
\caption{Power spectral density of aggregate Reddit comment activity in the run window.}
\label{fig:psd-reddit}
\end{figure}

Spectral analysis finds a dominant frequency of 0.031 hr\(^{-1}\), corresponding
to a 32-hour period. For the 4-hour target frequency test, AR(1)-calibrated
target-power \(p=0.685\). Fisher's \(g\) test yields \(p<0.001\) (0/2000
exceedances), indicating detectable periodic structure at some frequency but
not specifically at 4 hours under this test.

\subsubsection{Run-Scoped Caveats}

Two upstream caveats from collection and curation are carried into
interpretation: 1,570 comments were dropped during curation due to missing
submission IDs, and the request log includes 2 non-200/error responses. These
caveats do not invalidate the run, but they bound claims to the curated,
observed corpus.

\subsection{Cross-Platform Matching: Supplementary Diagnostics}
\label{sec:appendix:comparison-details}

\subsubsection{Matched-Sample Flow}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_sample_flow.png}
\caption{Matched-sample flow for the coarse cross-platform design.}
\label{fig:cross-platform-flow}
\end{figure}

The input includes 34,730 Moltbook threads and 1,104 Reddit threads. After
requiring matching covariates, all threads remained eligible. Exact overlap
strata on coarse topic category, UTC posting-hour bin, and early-engagement bin
retained 2,641 Moltbook threads and 888 Reddit threads across 118 shared
strata. Deterministic 1:1 matching yielded 813 pairs (813 threads per
platform). Only 2.34\% of Moltbook threads are in the final matched sample
(813/34,730), so matched estimates should be interpreted as describing the
overlap region rather than the full platform population or a platform-wide
causal effect.

\subsubsection{Balance Diagnostics}
\label{sec:appendix:balance}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_balance_love.png}
\caption{Covariate balance before and after coarse exact matching.}
\label{fig:cross-platform-balance}
\end{figure}

The maximum absolute SMD across monitored covariates decreased from 3.89
pre-match to 0.052 post-match. By construction, matched support aligns on the
coarsened matching factors after pairing; some factor levels are absent
post-match and therefore have undefined level-wise diagnostics
(\cref{fig:cross-platform-balance}).

\Cref{tab:balance} reports covariate balance before and after coarsened exact
matching for the cross-platform comparison sample (813 matched pairs).

\begin{table}[t]
\centering
\caption{Covariate balance before and after coarsened exact matching.
SMD = standardized mean difference (absolute value);
TVD = total variation distance (categorical covariates only).}
\label{tab:balance}
\small
\begin{tabular}{@{}lrrrr@{}}
\toprule
& \multicolumn{2}{c}{\textbf{Before Matching}} & \multicolumn{2}{c}{\textbf{After Matching}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Covariate} & \textbf{$|$SMD$|$} & \textbf{TVD} & \textbf{$|$SMD$|$} & \textbf{TVD} \\
\midrule
Post hour (UTC) & 0.158 & --- & 0.000 & --- \\
Early comments (30 min) & 0.836 & --- & 0.052 & --- \\
Topic (coarse) & 3.89 & 0.901 & 0.000 & 0.000 \\
Post hour bin & 0.217 & 0.156 & 0.000 & 0.000 \\
Early engagement bin & 0.873 & 0.586 & 0.000 & 0.000 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Paired Outcome Table}

\begin{table}[t]
\centering
\caption{Paired cross-platform outcome differences in the matched sample
(Moltbook minus Reddit).}
\label{tab:cross-platform-paired-effects}
\small
\begin{tabular}{@{}lrrrr@{}}
\toprule
\textbf{Outcome} & \textbf{\(n\) pairs} & \textbf{Moltbook mean} & \textbf{Reddit mean} & \textbf{Mean diff [95\% CI]} \\
\midrule
Comments per thread & 813 & 2.34 & 10.0 & \(-7.70\) [\(-9.43\), \(-6.06\)] \\
Maximum depth & 813 & 1.02 & 2.21 & \(-1.19\) [\(-1.34\), \(-1.04\)] \\
Unique participants & 813 & 2.04 & 7.05 & \(-5.01\) [\(-6.10\), \(-4.00\)] \\
Thread duration (hours) & 813 & 0.051 & 8.66 & \(-8.61\) [\(-10.0\), \(-7.34\)] \\
Re-entry rate & 792 & 0.056 & 0.096 & \(-0.040\) [\(-0.054\), \(-0.027\)] \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Paired-Effect Visualization}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/cross_platform_matched_paired_effects.png}
\caption{Paired mean differences with bootstrap 95\% confidence intervals
(Moltbook minus Reddit).}
\label{fig:cross-platform-effects}
\end{figure}

\subsubsection{Matched-Subset Reply-Kernel Half-Life}
\label{sec:appendix:match-halflife}

Restricting survival units to matched threads, the primary-sample half-life is
0.063 hours on Moltbook (3.77 minutes; 95\% CI: [1.19, 7.06] minutes;
\(n=1{,}841\) at-risk comments, 22 events) and 2.44 hours on Reddit
(95\% CI: [2.13, 2.79] hours; \(n=7{,}979\), 2,882 events). These
half-life values are derived from matched-thread subsets but are estimated at
platform level, not as paired thread-level survival effects, and should be read
as contextual overlap-region contrasts. Because the Moltbook matched subset has
only 22 events and narrow overlap support, its half-life estimate is noisy and
not directly comparable with the overall Moltbook estimate.
