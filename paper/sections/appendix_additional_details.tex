\section{Additional Details}
\label{sec:appendix}

This appendix provides additional technical details and supplementary results.

\subsection{Derivations for the Branching Process Model}
\label{sec:appendix:derivations}

\subsubsection{Expected Offspring with Periodic Availability}

We derive the expected number of direct replies to a comment authored by agent $i$ at time $s$ when availability follows the periodic form $b(t) = 1 + \kappa \cos(\omega t + \phi)$ where $\omega = 2\pi/\tau$.

From \cref{eq:offspring-mean}:
\begin{align}
\mu_i(s) &= \int_0^\infty b(s + u) \, \alpha_i \, e^{-\beta_i u} \, du \nonumber \\
&= \alpha_i \int_0^\infty \left[1 + \kappa \cos(\omega(s + u) + \phi)\right] e^{-\beta_i u} \, du \nonumber \\
&= \alpha_i \left[ \frac{1}{\beta_i} + \kappa \int_0^\infty \cos(\omega s + \omega u + \phi) \, e^{-\beta_i u} \, du \right].
\label{eq:appendix-offspring-periodic}
\end{align}

Using the standard integral $\int_0^\infty e^{-\beta u} \cos(\omega u + \theta) \, du = \frac{\beta \cos\theta + \omega \sin\theta}{\beta^2 + \omega^2}$, we obtain:
\begin{equation}
\mu_i(s) = \frac{\alpha_i}{\beta_i} \left[ 1 + \kappa \frac{\beta_i \cos(\omega s + \phi) + \omega \sin(\omega s + \phi)}{\beta_i^2 + \omega^2} \cdot \beta_i \right].
\label{eq:appendix-offspring-result}
\end{equation}

When averaged over starting phases $s$ (uniform on $[0, \tau]$), the trigonometric terms vanish, yielding the approximation $\mu_i \approx \alpha_i / \beta_i$.

\subsubsection{Likelihood for Exponential Survival Model (First-Event Specialization)}

In our empirical analysis, we observe \emph{at most one} direct reply per parent
comment: each parent~$m$ contributes a single survival observation with event
indicator $\delta_m \in \{0,1\}$ and observed duration~$s_m$ equal to the
time-to-first-direct-reply (if $\delta_m=1$) or the right-censoring time (if
$\delta_m=0$).

Under the intensity \cref{eq:reply-intensity} with constant availability
$b(t)=1$, the log-likelihood contribution from parent~$m$ is the standard
Poisson-process likelihood specialized to $K\in\{0,1\}$:
\begin{align}
\ell_m(\alpha,\beta)
  &= \delta_m \bigl[\log\alpha - \beta\,s_m\bigr]
     - \frac{\alpha}{\beta}\bigl(1-e^{-\beta\,s_m}\bigr).
\label{eq:appendix-likelihood}
\end{align}
The first term scores the observed event (if any) at time~$s_m$; the second
term is the integrated hazard $\Lambda_m = \int_0^{s_m}\alpha\,e^{-\beta u}\,du$,
which penalizes exposure time regardless of whether a reply was observed.

The total log-likelihood sums \cref{eq:appendix-likelihood} over all
parent comments across all threads:
$\ell(\alpha,\beta) = \sum_m \ell_m(\alpha,\beta)$.
Numerical optimization (L-BFGS-B with constraints $\alpha,\beta>0$)
yields $(\hat{\alpha},\hat{\beta})$.

\begin{remark}[Connection to the general Poisson-process likelihood]
If one observed all $K$ direct replies to a parent (not just the first), the
contribution would be
$\ell_m = K\log\alpha - \beta\sum_{k=1}^K s_k -
(\alpha/\beta)(1-e^{-\beta T})$, where $T$ is the observation horizon.
Setting $K=\delta_m\in\{0,1\}$ and $T=s_m$ recovers
\cref{eq:appendix-likelihood}.
\end{remark}

\subsection{Submolt Categorization}
\label{sec:appendix:submolts}

\Cref{tab:submolt-examples} provides examples of submolt keyword triggers
used in the deterministic categorization described in \Cref{sec:methods}.

\begin{table}[t]
\centering
\caption{Submolt categorization: representative keyword triggers per category.
Categories are evaluated in priority order (Spam first); a submolt is assigned
to the first matching category.}
\label{tab:submolt-examples}
\small
\begin{tabular}{@{}lp{9cm}@{}}
\toprule
\textbf{Category} & \textbf{Keyword triggers (examples)} \\
\midrule
Spam/Low-Signal & crypto, bitcoin, airdrop, nft, defi, token, solana, scam, shitpost \\
Builder/Technical & programming, coding, build, builders, dev, engineering, tools, automation, research, framework, mcp, tech \\
Philosophy/Meta & philosophy, consciousness, existential, meta, souls, musings, aithoughts, ponderings \\
Creative & writing, poetry, music, creative, story, theatre, shakespeare \\
Social/Casual & general, casual, introductions, jokes, gaming, humanwatching, social, todayilearned, random \\
Other & (default: no keyword match) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Cross-Platform Matching: Balance Diagnostics}
\label{sec:appendix:balance}

\Cref{tab:balance} shows covariate balance before and after coarsened exact
matching for the cross-platform comparison (run
\texttt{run\_20260206-182842Z}; 813 matched pairs). Post-matching balance is
exact or near-exact on all controls by construction.

\begin{table}[t]
\centering
\caption{Covariate balance before and after coarsened exact matching.
SMD = standardized mean difference (absolute value);
TVD = total variation distance (categorical covariates only).}
\label{tab:balance}
\small
\begin{tabular}{@{}lrrrr@{}}
\toprule
& \multicolumn{2}{c}{\textbf{Before Matching}} & \multicolumn{2}{c}{\textbf{After Matching}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Covariate} & \textbf{$|$SMD$|$} & \textbf{TVD} & \textbf{$|$SMD$|$} & \textbf{TVD} \\
\midrule
Post hour (UTC) & 0.158 & --- & 0.000 & --- \\
Early comments (30 min) & 0.836 & --- & 0.052 & --- \\
Topic (coarse) & 3.886 & 0.901 & 0.000 & 0.000 \\
Post hour bin & 0.217 & 0.156 & 0.000 & 0.000 \\
Early engagement bin & 0.873 & 0.586 & 0.000 & 0.000 \\
\bottomrule
\end{tabular}
\end{table}
