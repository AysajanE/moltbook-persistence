\section{Model and Estimands: Horizon-Limited Interaction Cascades}
\label{sec:model}

We model conversation dynamics on agent social networks with a generative framework
that combines age-dependent self-excitation, branching structure, and platform-level
availability modulation. We link platform mechanisms (exposure/resurfacing,
context persistence, and check-in cadence/synchronization) to observable
persistence outcomes through parameters \((\alpha,\beta,b(t),\mu)\). We then
define a minimal model and the estimands used in the empirical analysis.

The model is intentionally minimal: it provides identifiable measurement targets
and comparative-static predictions that can be checked against data. Richer
formulations for hierarchical heterogeneity and visibility-weighted reply assignment are provided in
\Cref{sec:model:extensions} in the appendix.

\subsection{Setting and Notation}
\label{sec:model:notation}

Let \(\mathcal{J}\) denote the set of threads (root posts). For thread
\(j\in\mathcal{J}\), events are indexed by \(n\in\{0,1,\ldots,N_j\}\), where
\(n=0\) is the root post and \(n\ge1\) are comments. Each event is
\((t_{jn},a_{jn},p_{jn})\), where \(t_{jn}\ge0\) is timestamp,
\(a_{jn}\in\mathcal{A}\) is author (an AI agent account), and \(p_{jn}\in\{0,\ldots,n-1\}\) is
parent index with \(p_{j0}=0\).

These parent links define a rooted reply tree \(T_j\). Depth is defined recursively:
\begin{equation}
\label{eq:depth}
d_{j0}=0, \qquad d_{jn}=d_{j,p_{jn}}+1 \quad (n\ge1).
\end{equation}
Maximum thread depth is \(D_j:=\max_{0\le n\le N_j} d_{jn}\).

Let \(\mathcal{H}_j(t)\) be thread history up to \(t\), and
\(N_j(t):=\sum_{n=1}^{N_j}\mathbf{1}\{t_{jn}\le t\}\) the cumulative
comment count by time \(t\).

\Cref{tab:notation} summarizes notation.

\begin{table}[t]
\centering
\caption{Summary of notation.}
\label{tab:notation}
\small
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Symbol} & \textbf{Description} \\
\midrule
$\calJ$ & Set of threads (root posts) \\
$\calA$ & Set of agents \\
$N_j$ & Number of comments in thread $j$ \\
$t_{jn}$ & Timestamp of event $n$ in thread $j$ \\
$a_{jn}$ & Author of event $n$ in thread $j$ \\
$p_{jn}$ & Parent index of event $n$ in thread $j$ \\
$d_{jn}$ & Depth of event $n$ in thread $j$ \\
$D_j$ & Maximum depth of thread $j$ \\
$\calH_j(t)$ & History of thread $j$ up to time $t$ \\
$b(t)$ & Aggregate availability function (attention clock) \\
$\alpha_i$ & Influence amplitude of agent $i$ \\
$\beta_i$ & Decay rate of agent $i$ \\
$h_i = \ln 2 / \beta_i$ & Half-life of agent $i$ \\
$\mu$ & Effective branching ratio \\
\bottomrule
\end{tabular}
\end{table}

\subsection{The Attention Clock: Availability and Staleness}
\label{sec:model:attention}

Agent interactions are governed by two distinct temporal mechanisms: platform-level
availability and within-thread staleness.

\begin{definition}[Availability]
\label{def:availability}
The \emph{aggregate availability function}
\(b:\mathbb{R}_{\ge0}\to\mathbb{R}_{\ge0}\) represents active-agent mass
at time \(t\), normalized so that
\(\bar b:=\frac{1}{L}\int_0^L b(t)\,dt=1\) over a long window.
\end{definition}

\begin{remark}[Observability limit]
\label{rem:availability-observability}
In observatory data, \(b(t)\) is latent because per-account heartbeat events are
not directly logged. We therefore infer heartbeat implications from aggregate
periodic signatures in timestamped activity, not from direct heartbeat-event
observation.
\end{remark}

For heartbeat-like scheduling, a tractable form is
\begin{equation}
\label{eq:availability-periodic}
b(t)=1+\kappa\cos\!\left(\frac{2\pi}{\tau}t+\phi\right), \qquad |\kappa|<1,
\end{equation}
where \(\tau\) is the characteristic check-in period, \(\kappa\) amplitude,
and \(\phi\) phase.

\begin{definition}[Staleness decay]
\label{def:staleness}
Conditional on exposure, reply propensity decays with age. For content authored by
agent \(i\) at time \(s\), staleness at \(t>s\) is
\(\exp[-\beta_i(t-s)]\), with \(\beta_i>0\).
\end{definition}

Availability \((\tau,\kappa,\phi)\) and staleness \((\beta_i)\) govern different
mechanisms and combine multiplicatively in event intensity.

\subsection{Temporal Dynamics: Self-Exciting Reply Processes}
\label{sec:model:temporal}

We model direct replies with an age-dependent Hawkes-type construction
\citep{hawkes1971spectra}.

\begin{definition}[Direct-reply intensity]
\label{def:reply-intensity}
Conditional on \(\mathcal{H}_j(t)\), each existing node \(m\) generates direct
replies as an inhomogeneous Poisson process with
\begin{equation}
\label{eq:reply-intensity}
\lambda_{j,m}(t\mid\mathcal{H}_j(t))
:= b(t)\,\alpha_{a_{jm}}\exp\!\left[-\beta_{a_{jm}}(t-t_{jm})\right]\mathbf{1}\{t>t_{jm}\},
\end{equation}
where \(\alpha_i>0\) is an effective exposure-weighted influence amplitude and
\(\beta_i>0\) decay rate. We write
\begin{equation}
\label{eq:alpha-exposure}
\alpha_i=\bar{\alpha}_i\,\xi_i,
\end{equation}
where \(\bar{\alpha}_i\) is baseline reply propensity and \(\xi_i\) is a latent
exposure multiplier that absorbs visibility/ranking and resurfacing/notification
effects in observational data.
\end{definition}

Total thread intensity is superposition,
\begin{equation}
\label{eq:total-intensity}
\lambda_j(t\mid\mathcal{H}_j(t)):=\sum_{m:t_{jm}<t}\lambda_{j,m}(t\mid\mathcal{H}_j(t)),
\end{equation}
and parent selection follows competing risks,
\begin{equation}
\label{eq:parent-selection}
\Prob(p_{jn}=m\mid t_{jn}=t,\mathcal{H}_j(t))
=\frac{\lambda_{j,m}(t\mid\mathcal{H}_j(t))}{\lambda_j(t\mid\mathcal{H}_j(t))}.
\end{equation}

\begin{remark}[Connection to standard Hawkes processes]
\label{rem:hawkes}
Marginalizing explicit parent labels yields a marked Hawkes process with kernel
\(g_i(\Delta)=\alpha_i e^{-\beta_i\Delta}\) modulated by \(b(t)\). Hawkes-style
self-excitation is well established in social-media dynamics, though kernel
families differ across applications \citep{crane2008robust,zhao2015seismic,rizoiu2017expecting}.
\end{remark}

\begin{remark}[Model Scope and Measurement Link]
\label{rem:model-scope}
Building on standard Hawkes and branching components, this formulation maps
platform mechanisms to observable persistence outcomes: heartbeat-style
activation enters through \(b(t)\), context-window staleness through \(\beta_i\),
and exposure/resurfacing through \(\alpha_i\) (via
\cref{eq:alpha-exposure}). These mechanisms are linked to direct-reply
incidence, conditional reply speed, depth-tail decay \((\mu)\), and spectral
power near \(1/\tau\). Reply-kernel half-life \((\ln 2/\beta)\) is retained as a
secondary timescale diagnostic. Mechanism interpretations below are
hypothesis-level and do not by themselves identify causal intervention effects.
\end{remark}

\subsection{Primary Estimands and Measurement Mapping}
\label{sec:model:estimands}
\label{sec:methods:def-est}

This subsection operationalizes the measurement map from mechanism parameters
\((\alpha,\beta,b(t),\mu)\) to estimands computed from observed timestamped reply trees.
Terminology in \Cref{sec:results,sec:discussion,sec:conclusion} follows this
estimand glossary.
For each candidate parent comment \(m\), let \(T_m\) denote first direct-reply
time (if any), \(C_m\) the right-censoring time from candidate-parent timestamp to
end of observable coverage, and
\[
s_m:=\min(T_m,C_m), \qquad \delta_m:=\mathbf{1}\{T_m\le C_m\}.
\]

The empirical specification is explicitly two-part:
\begin{align}
\delta_m &\sim \mathrm{Bernoulli}(\pi_m), \label{eq:two-part-incidence}\\
\log\!\left[-\log(1-\pi_m)\right] &= x_m^\top\eta, \label{eq:two-part-incidence-link}
\end{align}
where \(x_m\) includes observed parent-level covariates (here, submolt category
and claimed-status group indicators), and
\begin{equation}
T_m \mid (\delta_m=1,z_m)\sim F_\theta(\cdot\mid z_m),
\label{eq:two-part-timing}
\end{equation}
where \(F_\theta\) is a conditional timing family on positive support (Weibull
or lognormal-style alternatives are both admissible for the conditional-time
component).

Primary estimands are:
\begin{itemize}
\item \textbf{Direct-reply incidence:}
\(p_{\mathrm{obs}}:=\Prob(\delta_m=1)\), estimated empirically as
\(N_{\mathrm{reply}}/N_{\mathrm{risk}}\).
\item \textbf{Conditional reply timing:}
\(F_{T\mid \delta=1}(t):=\Prob(T_m\le t\mid \delta_m=1)\), summarized by
quantiles \((\tilde{s}_{0.5},\tilde{s}_{0.9},\tilde{s}_{0.95})\) and
short-window probabilities such as
\(\Prob(T_m\le 30\text{ s}\mid \delta_m=1)\) and
\(\Prob(T_m\le 5\text{ min}\mid \delta_m=1)\).
\item \textbf{Unconditional early-reply probability:}
\(\Prob(\delta_m=1, T_m\le t)\) for operational windows \(t\in\{30\text{ s}, 5\text{ min}\}\).
\item \textbf{Kernel timescale diagnostic:}
\(\beta\) in \cref{eq:reply-intensity}, reported as half-life
\(h=\ln 2/\beta\) (\cref{def:halflife}), interpreted as secondary to incidence
and conditional speed.
\item \textbf{Depth-tail decay summary:}
effective depth-tail slope estimate \(\hat{s}_{\mathrm{depth}}\) from
\(\log \Prob(D_j\ge k)\approx c+k\log s_{\mathrm{depth}}\), interpreted
descriptively because \cref{eq:depth-tail} is a bound.
\item \textbf{Periodicity detectability target:}
power concentration near \(f_\tau=1/\tau\) implied by \cref{prop:periodicity}.
\end{itemize}
We also report
\(p_\infty:=1-\exp(-\hat\alpha/\hat\beta)\) as a model-implied diagnostic
quantity, not as a direct empirical estimand.

\subsection{Interaction Half-Life}
\label{sec:model:halflife}

\begin{definition}[Agent-level half-life]
\label{def:halflife}
For agent \(i\), interaction half-life is
\begin{equation}
\label{eq:halflife}
h_i:=\frac{\ln 2}{\beta_i},
\end{equation}
so that \(e^{-\beta_i h_i}=1/2\).
\end{definition}

\begin{remark}[Estimation link]
Under \cref{eq:reply-intensity}, first-reply waiting times have hazard proportional
to \(e^{-\beta\Delta}\), so \(\beta\) is estimable by likelihood-based survival
methods from parent-relative reply times. In that analysis, each non-root
candidate parent comment is an at-risk unit (``at-risk comment'').
\end{remark}

\subsection{Structural Dynamics: Branching Process Interpretation}
\label{sec:model:branching}

The direct-reply process induces a branching interpretation in which each node
produces offspring over continuous time.

\subsubsection{Expected Offspring and Branching Ratio}

For a node authored by \(i\) at time \(s\), expected direct replies are
\begin{equation}
\label{eq:offspring-mean}
\mu_i(s):=\E[\#\{\text{direct replies}\}\mid a_{jm}=i,t_{jm}=s]
=\int_0^{\infty} b(s+u)\,\alpha_i e^{-\beta_i u}\,du.
\end{equation}
A phase-averaged or slowly varying approximation gives
\begin{equation}
\label{eq:offspring-approx}
\mu_i\approx \alpha_i\int_0^{\infty} e^{-\beta_i u}du=\frac{\alpha_i}{\beta_i}.
\end{equation}

\begin{proposition}[Influence--persistence trade-off]
\label{prop:tradeoff}
Expected replies are increasing in influence \((\alpha_i)\) and decreasing in
staleness decay \((\beta_i)\). Thus, higher persistence (lower \(\beta_i\)) can
sustain larger expected engagement even at moderate \(\alpha_i\).
\end{proposition}
Proof is provided in \Cref{app:proof-tradeoff}.

Define effective branching ratio
\begin{equation}
\label{eq:branching-ratio}
\mu(s):=\E_{i\sim\pi(s)}[\mu_i(s)],
\end{equation}
with author mixture \(\pi(s)\). Under normalization, \(\mu\approx\E[\alpha_i/\beta_i]\).

\subsubsection{Subcriticality and Expected Thread Size}

\begin{assumption}[Subcriticality]
\label{ass:subcritical}
The non-root effective branching ratio satisfies \(\mu<1\).
\end{assumption}

\begin{assumption}[Root-special branching regularity]
\label{ass:thread-size-regularity}
For thread-size calculations, \(N_j\) counts comments excluding the root post.
Let \(X_0\) denote the root offspring count, and let non-root offspring counts
be i.i.d. with mean \(\mu\) and finite expectation, independent across non-root
nodes and independent of \(X_0\).
\end{assumption}

\begin{proposition}[Expected comment count with root-special branching]
\label{prop:thread-size}
Let \(\mu_0\) be expected direct replies to the root post and \(\mu<1\) the mean
direct replies generated by a non-root comment. Then expected thread comment count is
\begin{equation}
\label{eq:expected-size}
\E[N_j]\approx\mu_0\sum_{k=0}^{\infty}\mu^k=\frac{\mu_0}{1-\mu}.
\end{equation}
The single-type special case \(\mu_0=\mu\) recovers \(\E[N_j]=\mu/(1-\mu)\).
\end{proposition}
Proof is provided in \Cref{app:proof-thread-size}.

In Moltbook-like trees, root fan-out is much larger than non-root reproduction,
so this root-special form is the relevant approximation.

\begin{remark}[Two-type branching interpretation]
\label{rem:two-type}
\Cref{prop:thread-size} corresponds to a two-type Galton--Watson process with root
offspring mean \(\mu_0\) and non-root mean \(\mu\). When
\(\mu_0\gg1\gg\mu\), trees are wide near depth 1 and shallow in deeper levels.
Depth-tail estimates should therefore be read as an approximate non-root
effective reproduction signal via tail decay, not an exact identity.
\end{remark}

\subsubsection{Depth Distribution and Tail Bounds}

\begin{proposition}[Depth tail bound]
\label{prop:depth-bound}
Under the single-type approximation, let \(Z_k\) be the generation-\(k\)
population size in the associated Galton--Watson process (\(Z_0=1\) at the
root). Then
\begin{equation}
\label{eq:depth-tail}
\Prob(D_j\ge k)\le \E[Z_k]=\mu^k.
\end{equation}
\end{proposition}

\begin{proof}
If \(D_j\ge k\), then generation-\(k\) population \(Z_k\ge1\). By Markov's
inequality, \(\Prob(D_j\ge k)\le\E[Z_k]\). Under mean offspring \(\mu\),
\(\E[Z_k]=\mu^k\).
\end{proof}

\begin{remark}[Implication for shallow threads]
\label{rem:shallow}
Deep threads become exponentially unlikely unless \(\mu\) is near one; high decay
rates (large \(\beta_i\)) imply small \(\mu_i\) and thus shallow trees.
\end{remark}

\begin{remark}[Interpretation of \(\mu\) in depth tails]
\label{rem:mu-tail-interpretation}
\Cref{eq:depth-tail} is an upper bound, not an exact identity for the empirical
depth tail. Accordingly, the effective depth-tail slope estimate
\(\hat{s}_{\mathrm{depth}}\), obtained from
\(\log \Prob(D_j\ge k)\approx c+k\log s_{\mathrm{depth}}\), should be read as a
descriptive summary motivated by the bound, rather than an exact
equality-based estimator of reproduction mean or branching ratio.
\end{remark}

\subsection{Reciprocity, Re-Entry, and Agent Heterogeneity}
\label{sec:model:heterogeneity}

For thread \(j\), define directed interaction edges
\begin{equation}
\label{eq:edge-set}
E_j:=\{(u,v): \exists n\ge1 \text{ with } a_{jn}=u,\ a_{j,p_{jn}}=v,\ u\neq v\}.
\end{equation}
Multiple replies in the same direction are collapsed to a single directed edge.
Let
\begin{equation}
\label{eq:dyad-set}
\Delta_j:=\{\{u,v\}: (u,v)\in E_j \ \text{or}\ (v,u)\in E_j\}
\end{equation}
be the unordered dyad set with at least one observed directional reply. We define
thread-level reciprocity as
\begin{equation}
\label{eq:reciprocity-rate}
\mathrm{R}_j
:=\frac{1}{|\Delta_j|}\sum_{\{u,v\}\in\Delta_j}
\mathbf{1}\{(u,v)\in E_j\ \text{and}\ (v,u)\in E_j\},
\end{equation}
with pooled reciprocity obtained by summing numerator and denominator over
threads.

We quantify sustained participation with thread-level re-entry rate
\begin{equation}
\label{eq:reentry-rate}
\mathrm{RE}_j
:=\frac{\#\{n: a_{jn}\in\{a_{j1},\ldots,a_{j,n-1}\}\}}{N_j}.
\end{equation}
Low \(\mathrm{RE}_j\) indicates broadcast-style interaction; higher values
indicate repeated participation within threads.
This definition uses comment-stream history only: root-post authorship
\(a_{j0}\) is excluded from the prior-author set unless that account appears in
the comment sequence. The scope aligns the numerator and denominator on
non-root comments (\(N_j\)).

Observed agent activity is heterogeneous. In this manuscript, empirical analysis
uses stratified pooled summaries by observable proxies (claim status,
follower-count bins), while richer hierarchical and re-entry-augmented
specifications are formalized in \Cref{sec:model:extensions}.

\subsection{Periodicity Signatures from the Attention Clock}
\label{sec:model:periodicity}

\begin{proposition}[Periodic mean intensity and periodogram detectability]
\label{prop:periodicity}
Suppose aggregate activity is generated by a point process with conditional
intensity \(\lambda(t)=b(t)\,g(t)\), where \(b(t)\) is deterministic, bounded,
and \(\tau\)-periodic, and \(g(t)\) is nonnegative and adapted with
\(\E[g(t)]<\infty\) for all \(t\). If \(\E[g(t)]\) is \(\tau\)-periodic (in
particular, approximately constant on the \(\tau\)-scale), then
\(m(t):=\E[\lambda(t)]\) is \(\tau\)-periodic. Consequently, for long-window
binned counts, expected periodogram/PSD estimates exhibit elevated power near
frequencies \(\ell/\tau\) (\(\ell\in\mathbb{Z}\)), up to binning,
finite-sample, and leakage effects.
\end{proposition}
Proof is provided in \Cref{app:proof-periodicity}.

This prediction is tested with PSD-based target-frequency inference and
agent-level autocorrelation diagnostics.

\subsection{Platform Design Levers and Comparative Statics}
\label{sec:model:mechanisms}

Let \(u=(u_{\mathrm{vis}},u_{\mathrm{res}},u_{\mathrm{mem}},
u_{\mathrm{sync}},u_{\mathrm{cad}})\) denote platform settings for visibility
weighting, resurfacing/notifications, memory scaffolding, synchronization policy,
and scheduled check-in cadence. Consistent with \cref{eq:alpha-exposure}, we model
\(u_{\mathrm{vis}}\) and \(u_{\mathrm{res}}\) as levers on the exposure multiplier
inside \(\alpha_i\). For decision-support use, this block maps lever inputs to
predicted persistence outputs and their trade-offs. A stylized mapping from
these design settings to model parameters is
\begin{align}
\alpha_i(u) &=
\bar{\alpha}_i^{(0)}\,\xi_i(u), \qquad
\xi_i(u):=\exp\!\left(
\theta_{i,\mathrm{vis}}u_{\mathrm{vis}}+
\theta_{i,\mathrm{res}}u_{\mathrm{res}}
\right), \label{eq:lever-alpha}\\
\beta_i(u) &=
\beta_i^{(0)}\exp\!\left(-\theta_{i,\mathrm{mem}}u_{\mathrm{mem}}\right),
\label{eq:lever-beta}\\
b(t;u) &= 1+\kappa(u_{\mathrm{sync}})
\cos\!\left(\frac{2\pi}{\tau(u_{\mathrm{cad}})}t+\phi\right),
\quad |\kappa(u_{\mathrm{sync}})|<1,
\label{eq:lever-b}
\end{align}
with \(\theta_{\cdot,\cdot}\ge 0\). Here, stronger memory scaffolding lowers
effective decay (\(\beta_i\downarrow\)); resurfacing and visibility increase
effective exposure (\(\alpha_i\uparrow\)); synchronization and cadence govern the
shape of \(b(t)\) through \(\kappa(\cdot)\) and \(\tau(\cdot)\).

Under design \(u\), the expected direct offspring of node \((i,s)\) is
\begin{equation}
\label{eq:lever-mu-i}
\mu_i(s;u)=\int_0^{\infty} b(s+v;u)\,\alpha_i(u)\,e^{-\beta_i(u)v}\,dv.
\end{equation}

\begin{assumption}[Monotone design change]
\label{ass:lever-monotone}
For two designs \(A\) and \(B\), suppose for all \(i,t\):
\(\alpha_i(B)\ge\alpha_i(A)\), \(\beta_i(B)\le\beta_i(A)\), and
\(b(t;B)\ge b(t;A)\), with at least one strict inequality on a set of positive
measure.
\end{assumption}

\begin{proposition}[Lever monotonicity of effective reproduction]
\label{prop:lever-mu-monotone}
Under \Cref{ass:lever-monotone}, \(\mu_i(s;B)\ge\mu_i(s;A)\) for all \(i,s\).
For fixed author mixture \(\pi(s)\), the aggregate non-root reproduction satisfies
\(\mu(B)\ge\mu(A)\).
\end{proposition}

\begin{proof}
In \Cref{eq:lever-mu-i}, the integrand is nonnegative and weakly larger under
design \(B\) pointwise in \(v\), so the integral is weakly larger. Averaging over
\(i\sim\pi(s)\) preserves the inequality.
\end{proof}

\begin{corollary}[Stylized memory/resurfacing comparative-static hypothesis on depth and size]
\label{cor:lever-size-depth}
Assume \Cref{ass:thread-size-regularity} and \(0\le\mu(A)\le\mu(B)<1\), with
\(\mu_0(B)\ge\mu_0(A)\). Then
\begin{equation}
\label{eq:lever-size-monotone}
\E[N_j\mid B]=\frac{\mu_0(B)}{1-\mu(B)}
\ge
\frac{\mu_0(A)}{1-\mu(A)}=\E[N_j\mid A].
\end{equation}
For a depth comparison only, add the local assumption that non-root offspring are
Poisson with means \(\mu(A)\) and \(\mu(B)\), coupled by thinning across designs.
Under this local assumption,
\(\Prob(D_j\ge k\mid B)\ge\Prob(D_j\ge k\mid A)\) for all \(k\), hence
\(\E[D_j\mid B]\ge\E[D_j\mid A]\).
\end{corollary}

\begin{proof}[Proof sketch]
Equation \eqref{eq:lever-size-monotone} follows from \Cref{prop:thread-size}. For
depth under the local Poisson condition, couple offspring by thinning: a \(\mathrm{Poisson}(\mu(A))\)
offspring count is obtained by thinning \(\mathrm{Poisson}(\mu(B))\) with retention
probability \(\mu(A)/\mu(B)\). Recursing this coupling over generations makes the
tree under \(A\) a subtree of the tree under \(B\) almost surely, implying the
depth and size inequalities.
\end{proof}

These are comparative-static decision-support implications of the model, not
identified causal effects from observational data. In the empirical sections,
intervention language is therefore interpreted as mechanism-consistent
hypotheses.
