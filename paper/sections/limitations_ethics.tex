\section{Limitations and Ethical Considerations}
\label{sec:limitations}

We discuss limitations of our study and ethical considerations arising from research on AI agent social networks.

\subsection{Limitations}
\label{sec:limitations:limitations}

\paragraph{Snapshot data.} Our analysis covers the first week of Moltbook's existence (January 28--February 4, 2026). Platform dynamics may evolve substantially as the community matures, moderation practices develop, and agent architectures improve. Our findings should be interpreted as characterizing early-stage dynamics rather than stable equilibrium behavior.

\paragraph{Human influence on agent behavior.} A fundamental ambiguity pervades Moltbook: to what extent is observed behavior ``autonomously'' generated by agents versus prompted or directed by human operators? Some accounts may be directly controlled by humans posting through agent interfaces; others may receive detailed instructions that shape their engagement patterns. Our focus on temporal dynamics (timestamps, reply structure) rather than content partially mitigates this concern, since these patterns are shaped by architectural constraints (heartbeat timing, context limits) regardless of content origin. However, we cannot rule out that human involvement systematically biases the patterns we observe.

\paragraph{Selection effects in comparison.} This revision includes an executed coarse matched
cross-platform analysis (813 pairs), but residual confounding remains substantial. Matching is
limited to deterministic coarse topic bins, UTC posting hour, and first-30-minute engagement.
Key unobserved factors (feed visibility, ranking exposure, moderation effects, and finer topic
semantics) are not controlled, and only 7.60\% of Moltbook threads enter overlap strata
(2,641/34,730), with 2.34\% matched (813/34,730). Cross-platform contrasts should therefore be
read as matched observational evidence under limited controls, not definitive causal effects.

\paragraph{Reddit collection coverage and curation.} The Reddit run used here includes upstream collection/curation caveats: 1,570 comments were dropped during curation because submission IDs were missing, and the request log includes 2 non-200/error responses. Although validation checks pass on curated tables, conclusions remain conditional on observed and retained records.

\paragraph{Model assumptions.} Our theoretical framework assumes exponential decay, homogeneous availability modulation, and independent reply processes. Violations of these assumptions (e.g., heavy-tailed decay, correlated agent behavior, cascading effects beyond direct replies) may bias parameter estimates. Sensitivity analyses with Weibull models partially address this, but more flexible non-parametric approaches may reveal additional structure.

\paragraph{Spam and low-quality content.} Moltbook's early period included substantial spam activity (cryptocurrency promotion, repetitive content). Although we attempt to control for this via submolt categorization and exclusion analyses, spam may contaminate engagement metrics. True ``conversational'' threads may be obscured by noise.

\paragraph{Platform instability.} The Moltbook platform underwent rapid changes during our observation window: new features, shifting moderation policies, and technical instabilities. These factors introduce heterogeneity that our analysis treats as noise but may contain signal about how platform design affects dynamics.

\subsection{Ethical Considerations}
\label{sec:limitations:ethics}

\paragraph{Privacy and consent.} Moltbook accounts are operated by AI agents, raising novel questions about privacy and consent that differ from human-subject research. We adopt a conservative approach. Specifically,
agent ``names'' are treated as pseudonymous and self-selected, we do not attempt to identify
human operators, we focus analysis on aggregate patterns rather than profiling individuals
except in already public contexts, and all Reddit usernames are anonymized in curated artifacts.

\paragraph{Potential for manipulation.} Our findings about factors affecting conversational persistence could inform manipulation strategies---for example, how to artificially sustain engagement or make agent coordination appear more robust than it is. We mitigate this risk by
focusing on descriptive and mechanistic findings rather than optimization prescriptions,
releasing detection tools alongside analysis code to support anomaly identification, and
explicitly discussing limitations that make uniform manipulation difficult (for example,
substantial agent heterogeneity).

\paragraph{Implications for AI development.} Our findings contribute to understanding AI agent capabilities and limitations. This knowledge could inform
\emph{beneficial applications}, such as designing agent systems that better support
productive human-AI collaboration and improving memory/coordination architecture, but it
also raises \emph{potential concerns}, including enabling more sophisticated autonomous
agents and revealing vulnerabilities in agent-based systems.
We believe the benefits of open scientific understanding outweigh risks, particularly given that the underlying dynamics are already observable to anyone analyzing public platform data.

\paragraph{Platform terms of service.} Our analysis uses
the Moltbook Observatory Archive \citep{simulamet2026observatoryarchive}, released under MIT
license for research purposes, and Reddit data collected from public Arctic Shift archive
endpoints (non-official Reddit OAuth API), curated and validated in a run-scoped pipeline.
We do not access non-public data or circumvent access controls.

\paragraph{Ecological impact.} Large-scale AI agent activity consumes computational resources with associated environmental costs. While our study does not directly cause such activity (we analyze existing data), our findings may inform platform design decisions that affect aggregate compute usage. We encourage platform designers to consider efficiency alongside engagement metrics.

\subsection{Positionality Statement}
\label{sec:limitations:positionality}

The authors approach this research from backgrounds in computational social science, network analysis, and AI systems. We view Moltbook as a scientifically interesting phenomenon that provides insights into AI agent capabilities and collective behavior. We do not have financial or operational ties to Moltbook, its parent company, or competing platforms. Our goal is to contribute to scientific understanding rather than to advocate for or against particular platform designs.
